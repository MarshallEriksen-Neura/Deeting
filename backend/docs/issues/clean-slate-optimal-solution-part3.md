# ä»é›¶å¼€å§‹çš„æœ€ä¼˜è®¡è´¹ä¸é…é¢æ–¹æ¡ˆ (Part 3)

## ğŸ’» æ ¸å¿ƒä»£ç å®ç° (ç»­)

### 4. æµå¼è®¡è´¹å›è°ƒ (API å±‚)

```python
# backend/app/api/v1/external/gateway.py

async def _stream_billing_callback(
    ctx: WorkflowContext,
    accumulator: StreamTokenAccumulator,
) -> None:
    """
    æµå¼è®¡è´¹å›è°ƒï¼šæäº¤ PENDING äº¤æ˜“
    
    æ–°é€»è¾‘ï¼š
    1. ä» Context è·å– pending_trace_id
    2. ä½¿ç”¨ tiktoken ç²¾ç¡®è®¡ç®— output tokens
    3. è°ƒç”¨ BillingRepository.commit_pending_transaction()
    4. è®°å½•ç”¨é‡ï¼ˆé€šè¿‡ Celery ä»»åŠ¡ï¼‰
    """
    # æ£€æŸ¥æ˜¯å¦æœ‰ PENDING äº¤æ˜“
    pending_trace_id = ctx.get("billing", "pending_trace_id")
    if not pending_trace_id:
        logger.warning(f"No pending transaction for stream trace_id={ctx.trace_id}")
        return
    
    # è·å–å®šä»·é…ç½®
    pricing = ctx.get("billing", "pricing_config") or {}
    if not pricing:
        logger.info(f"No pricing config, skip billing trace_id={ctx.trace_id}")
        return
    
    # ä½¿ç”¨å¢å¼ºçš„ token è®¡ç®—ï¼ˆä¼˜å…ˆçº§ï¼šusage > tiktoken > ä¼°ç®—ï¼‰
    output_tokens = accumulator.calculate_output_tokens(ctx.requested_model)
    
    # æ›´æ–° Context ä¸­çš„ billing ä¿¡æ¯
    ctx.billing.input_tokens = accumulator.input_tokens
    ctx.billing.output_tokens = output_tokens
    
    # æäº¤ PENDING äº¤æ˜“
    if ctx.db_session:
        try:
            repo = BillingRepository(ctx.db_session)
            transaction = await repo.commit_pending_transaction(
                trace_id=pending_trace_id,
                input_tokens=accumulator.input_tokens,
                output_tokens=output_tokens,
                input_price=Decimal(str(pricing.get("input_per_1k", 0))),
                output_price=Decimal(str(pricing.get("output_per_1k", 0))),
                allow_negative=True,  # æµå¼å…è®¸è´Ÿå€¼
            )
            
            # æ›´æ–° Context
            ctx.billing.total_cost = float(transaction.amount)
            ctx.billing.currency = pricing.get("currency", "USD")
            
            # è®°å½•è®¡ç®—æ–¹å¼ï¼ˆç”¨äºç›‘æ§ï¼‰
            calculation_method = "usage" if accumulator._has_usage else (
                "tiktoken" if accumulator._collected_text else "estimated"
            )
            
            logger.info(
                f"Stream billing committed trace_id={ctx.trace_id} "
                f"method={calculation_method} "
                f"tokens={ctx.billing.total_tokens} "
                f"cost={transaction.amount:.6f}"
            )
            
            # ç›‘æ§æŒ‡æ ‡
            from app.core.monitoring import metrics
            metrics.counter(
                "stream.token_calculation",
                tags={"method": calculation_method}
            )
            
        except Exception as e:
            logger.error(f"Stream billing commit failed trace_id={ctx.trace_id}: {e}")
            # å‘é€å‘Šè­¦
            from app.core.monitoring import alert_billing_failure
            alert_billing_failure(ctx.trace_id, str(e))
    
    # å¼‚æ­¥è®°å½•ç”¨é‡ï¼ˆé€šè¿‡ Celeryï¼‰
    try:
        from app.tasks.billing import record_usage_task
        
        usage_data = {
            "tenant_id": str(ctx.tenant_id) if ctx.tenant_id else None,
            "api_key_id": str(ctx.api_key_id) if ctx.api_key_id else None,
            "trace_id": ctx.trace_id,
            "model": ctx.requested_model,
            "capability": ctx.capability,
            "input_tokens": accumulator.input_tokens,
            "output_tokens": output_tokens,
            "total_cost": ctx.billing.total_cost,
            "currency": ctx.billing.currency,
            "provider": ctx.upstream_result.provider,
            "latency_ms": ctx.upstream_result.latency_ms,
            "is_stream": True,
            "stream_completed": accumulator.is_completed,
            "stream_error": accumulator.error,
        }
        
        record_usage_task.delay(usage_data)
        
    except Exception as e:
        logger.warning(f"Usage task dispatch failed trace_id={ctx.trace_id}: {e}")
```


### 5. StreamTokenAccumulator å¢å¼º (ç²¾ç¡®è®¡ç®—)

```python
# backend/app/services/workflow/steps/upstream_call.py

@dataclass
class StreamTokenAccumulator:
    """
    æµå¼ Token ç´¯è®¡å™¨ï¼ˆå¢å¼ºç‰ˆï¼‰
    
    ä¼˜å…ˆçº§ï¼š
    1. ä¸Šæ¸¸è¿”å›çš„ usage ä¿¡æ¯ï¼ˆæœ€å‡†ç¡®ï¼‰
    2. tiktoken ç²¾ç¡®è®¡ç®—ï¼ˆè¯¯å·® < 1%ï¼‰
    3. åŸºäº chunks ä¼°ç®—ï¼ˆå…œåº•ï¼‰
    """
    input_tokens: int = 0
    output_tokens: int = 0
    chunks_count: int = 0
    is_completed: bool = False
    error: str | None = None
    finish_reason: str | None = None
    model: str | None = None
    
    # æ–°å¢ï¼šæ”¶é›†çš„æ–‡æœ¬å†…å®¹
    _collected_text: str = ""
    _has_usage: bool = False
    
    def parse_sse_chunk(self, chunk: bytes) -> None:
        """è§£æ SSE å—å¹¶ç´¯è®¡ token"""
        try:
            text = chunk.decode("utf-8")
            for line in text.split("\n"):
                line = line.strip()
                if not line or line == "data: [DONE]":
                    if line == "data: [DONE]":
                        self.is_completed = True
                    continue
                
                if line.startswith("data: "):
                    json_str = line[6:]
                    try:
                        data = json.loads(json_str)
                        self.chunks_count += 1
                        
                        # æå– model
                        if not self.model and "model" in data:
                            self.model = data["model"]
                        
                        # æå– finish_reason
                        if data.get("choices"):
                            choice = data["choices"][0]
                            if choice.get("finish_reason"):
                                self.finish_reason = choice["finish_reason"]
                            
                            # æ”¶é›†æ–‡æœ¬å†…å®¹ï¼ˆç”¨äº tiktoken è®¡ç®—ï¼‰
                            delta = choice.get("delta", {})
                            if "content" in delta:
                                self._collected_text += delta["content"]
                        
                        # æå– usageï¼ˆä¼˜å…ˆä½¿ç”¨ï¼‰
                        if "usage" in data:
                            usage = data["usage"]
                            self.input_tokens = usage.get("prompt_tokens", 0)
                            self.output_tokens = usage.get("completion_tokens", 0)
                            self._has_usage = True
                    
                    except json.JSONDecodeError:
                        pass
        except Exception as e:
            self.error = str(e)
    
    def calculate_output_tokens(self, model: str | None = None) -> int:
        """
        è®¡ç®—è¾“å‡º tokensï¼ˆä¼˜å…ˆçº§ï¼šusage > tiktoken > ä¼°ç®—ï¼‰
        """
        # 1. ä¼˜å…ˆä½¿ç”¨ä¸Šæ¸¸è¿”å›çš„ usage
        if self._has_usage and self.output_tokens > 0:
            return self.output_tokens
        
        # 2. ä½¿ç”¨ tiktoken ç²¾ç¡®è®¡ç®—
        if self._collected_text:
            try:
                import tiktoken
                
                # æ ¹æ®æ¨¡å‹é€‰æ‹©ç¼–ç å™¨
                model_name = model or self.model or "gpt-3.5-turbo"
                if "gpt-4" in model_name:
                    encoding = tiktoken.encoding_for_model("gpt-4")
                elif "gpt-3.5" in model_name:
                    encoding = tiktoken.encoding_for_model("gpt-3.5-turbo")
                elif "claude" in model_name:
                    encoding = tiktoken.get_encoding("cl100k_base")
                else:
                    encoding = tiktoken.get_encoding("cl100k_base")
                
                tokens = len(encoding.encode(self._collected_text))
                logger.debug(f"Calculated tokens using tiktoken: {tokens}")
                return tokens
                
            except Exception as e:
                logger.warning(f"tiktoken calculation failed: {e}")
        
        # 3. æœ€åä½¿ç”¨ä¼°ç®—
        estimated = max(1, self.chunks_count * 3)
        logger.warning(
            f"Using estimated tokens: {estimated} "
            f"(chunks={self.chunks_count}, no usage info)"
        )
        return estimated
```



---

## ğŸ”§ é…ç½®æ–‡ä»¶

### 1. Redis Lua è„šæœ¬åŠ è½½å™¨

```python
# backend/app/core/cache.py

import os
from pathlib import Path
from typing import Dict

class Cache:
    def __init__(self):
        self._redis = None
        self._script_shas: Dict[str, str] = {}
    
    async def preload_scripts(self) -> None:
        """é¢„åŠ è½½ Lua è„šæœ¬"""
        if not self._redis:
            logger.warning("Redis not available, skip script preload")
            return
        
        scripts_dir = Path(__file__).parent / "redis_scripts"
        if not scripts_dir.exists():
            logger.warning(f"Scripts directory not found: {scripts_dir}")
            return
        
        # åŠ è½½æ‰€æœ‰ .lua è„šæœ¬
        for script_file in scripts_dir.glob("*.lua"):
            script_name = script_file.stem
            script_content = script_file.read_text()
            
            try:
                sha = await self._redis.script_load(script_content)
                self._script_shas[script_name] = sha
                logger.info(f"Loaded Lua script: {script_name} -> {sha}")
            except Exception as e:
                logger.error(f"Failed to load script {script_name}: {e}")
    
    def get_script_sha(self, script_name: str) -> str | None:
        """è·å–è„šæœ¬ SHA"""
        return self._script_shas.get(script_name)

# å…¨å±€å®ä¾‹
cache = Cache()
```

### 2. ç¼“å­˜é”®å®šä¹‰

```python
# backend/app/core/cache_keys.py

class CacheKeys:
    """ç¼“å­˜é”®å®šä¹‰"""
    
    @staticmethod
    def quota_hash(tenant_id: str) -> str:
        """ç§Ÿæˆ·é…é¢ Hash"""
        return f"gw:quota:tenant:{tenant_id}"
    
    @staticmethod
    def billing_deduct_idempotency(tenant_id: str, trace_id: str) -> str:
        """è®¡è´¹å¹‚ç­‰é”®"""
        return f"gw:billing:idempotent:{tenant_id}:{trace_id}"
    
    @staticmethod
    def rate_limit_rpm(tenant_id: str, minute: str) -> str:
        """RPM é™æµé”®"""
        return f"gw:ratelimit:rpm:{tenant_id}:{minute}"
    
    @staticmethod
    def rate_limit_tpm(tenant_id: str, minute: str) -> str:
        """TPM é™æµé”®"""
        return f"gw:ratelimit:tpm:{tenant_id}:{minute}"
    
    @staticmethod
    def session_lock(session_id: str) -> str:
        """ä¼šè¯é”"""
        return f"gw:lock:session:{session_id}"
```

### 3. ç›‘æ§æŒ‡æ ‡å®šä¹‰

```python
# backend/app/core/monitoring.py

from prometheus_client import Counter, Histogram, Gauge

# é…é¢æ£€æŸ¥
quota_check_passed = Counter(
    "quota_check_passed_total",
    "é…é¢æ£€æŸ¥é€šè¿‡æ¬¡æ•°"
)

quota_check_failed = Counter(
    "quota_check_failed_total",
    "é…é¢æ£€æŸ¥å¤±è´¥æ¬¡æ•°",
    ["reason"]  # balance, daily, monthly
)

quota_check_duration = Histogram(
    "quota_check_duration_seconds",
    "é…é¢æ£€æŸ¥è€—æ—¶"
)

# è®¡è´¹
billing_deduct_success = Counter(
    "billing_deduct_success_total",
    "è®¡è´¹æˆåŠŸæ¬¡æ•°"
)

billing_deduct_failure = Counter(
    "billing_deduct_failure_total",
    "è®¡è´¹å¤±è´¥æ¬¡æ•°",
    ["reason"]  # insufficient_balance, redis_error, db_error
)

billing_duration = Histogram(
    "billing_duration_seconds",
    "è®¡è´¹è€—æ—¶"
)

billing_idempotent_hit = Counter(
    "billing_idempotent_hit_total",
    "å¹‚ç­‰é”®å‘½ä¸­æ¬¡æ•°"
)

# æµå¼è®¡è´¹
stream_pending_created = Counter(
    "billing_stream_pending_created_total",
    "æµå¼ PENDING äº¤æ˜“åˆ›å»ºæ¬¡æ•°"
)

stream_committed = Counter(
    "billing_stream_committed_total",
    "æµå¼äº¤æ˜“æäº¤æ¬¡æ•°"
)

stream_failed = Counter(
    "billing_stream_failed_total",
    "æµå¼äº¤æ˜“å¤±è´¥æ¬¡æ•°"
)

stream_token_calculation = Counter(
    "stream_token_calculation_total",
    "æµå¼ token è®¡ç®—æ–¹å¼",
    ["method"]  # usage, tiktoken, estimated
)

stream_token_accuracy = Histogram(
    "stream_token_accuracy_percent",
    "æµå¼ token è®¡ç®—å‡†ç¡®ç‡"
)

# Redis ä¸ DB ä¸€è‡´æ€§
quota_redis_db_diff = Gauge(
    "quota_redis_db_diff",
    "Redis ä¸ DB é…é¢å·®å¼‚",
    ["tenant_id"]
)

# Redis Lua è„šæœ¬
redis_lua_duration = Histogram(
    "redis_lua_duration_seconds",
    "Redis Lua è„šæœ¬è€—æ—¶",
    ["script"]  # quota_check, quota_deduct
)
```



---

## ğŸ§ª æµ‹è¯•ç”¨ä¾‹

### 1. QuotaCheckStep å•å…ƒæµ‹è¯•

```python
# backend/tests/test_quota_check.py

import pytest
from decimal import Decimal
from app.services.workflow.steps.quota_check import QuotaCheckStep, QuotaExceededError
from app.services.orchestrator.context import WorkflowContext, Channel

@pytest.mark.asyncio
async def test_quota_check_pass(db_session, redis_client):
    """æµ‹è¯•é…é¢æ£€æŸ¥é€šè¿‡"""
    # å‡†å¤‡æ•°æ®
    tenant_id = "test-tenant-123"
    quota = await create_test_quota(
        db_session,
        tenant_id=tenant_id,
        balance=Decimal("100.00"),
        daily_quota=1000,
        daily_used=0,
        monthly_quota=30000,
        monthly_used=0,
    )
    
    # åˆ›å»ºä¸Šä¸‹æ–‡
    ctx = WorkflowContext(
        channel=Channel.EXTERNAL,
        capability="chat",
        requested_model="gpt-3.5-turbo",
        db_session=db_session,
        tenant_id=tenant_id,
    )
    
    # æ‰§è¡Œæ£€æŸ¥
    step = QuotaCheckStep()
    result = await step.execute(ctx)
    
    # éªŒè¯ç»“æœ
    assert result.status == StepStatus.SUCCESS
    assert ctx.get("quota_check", "remaining_balance") == 100.00
    assert ctx.get("quota_check", "daily_remaining") == 1000
    assert ctx.get("quota_check", "monthly_remaining") == 30000


@pytest.mark.asyncio
async def test_quota_check_insufficient_balance(db_session, redis_client):
    """æµ‹è¯•ä½™é¢ä¸è¶³"""
    # å‡†å¤‡æ•°æ®
    tenant_id = "test-tenant-123"
    quota = await create_test_quota(
        db_session,
        tenant_id=tenant_id,
        balance=Decimal("0.01"),  # ä½™é¢ä¸è¶³
        daily_quota=1000,
        daily_used=0,
    )
    
    # åˆ›å»ºä¸Šä¸‹æ–‡
    ctx = WorkflowContext(
        channel=Channel.EXTERNAL,
        capability="chat",
        requested_model="gpt-3.5-turbo",
        db_session=db_session,
        tenant_id=tenant_id,
    )
    
    # è®¾ç½®å®šä»·ï¼ˆä¼°ç®—è´¹ç”¨ä¼šè¶…è¿‡ä½™é¢ï¼‰
    ctx.set("routing", "pricing_config", {
        "input_per_1k": 0.001,
        "output_per_1k": 0.002,
    })
    
    # æ‰§è¡Œæ£€æŸ¥
    step = QuotaCheckStep()
    result = await step.execute(ctx)
    
    # éªŒè¯ç»“æœ
    assert result.status == StepStatus.FAILED
    assert ctx.error_code == "QUOTA_BALANCE_EXCEEDED"


@pytest.mark.asyncio
async def test_quota_check_daily_exceeded(db_session, redis_client):
    """æµ‹è¯•æ—¥é…é¢è¶…é™"""
    # å‡†å¤‡æ•°æ®
    tenant_id = "test-tenant-123"
    quota = await create_test_quota(
        db_session,
        tenant_id=tenant_id,
        balance=Decimal("100.00"),
        daily_quota=1000,
        daily_used=1000,  # æ—¥é…é¢å·²ç”¨å®Œ
    )
    
    # åˆ›å»ºä¸Šä¸‹æ–‡
    ctx = WorkflowContext(
        channel=Channel.EXTERNAL,
        capability="chat",
        requested_model="gpt-3.5-turbo",
        db_session=db_session,
        tenant_id=tenant_id,
    )
    
    # æ‰§è¡Œæ£€æŸ¥
    step = QuotaCheckStep()
    result = await step.execute(ctx)
    
    # éªŒè¯ç»“æœ
    assert result.status == StepStatus.FAILED
    assert ctx.error_code == "QUOTA_DAILY_EXCEEDED"
```

### 2. BillingStep å•å…ƒæµ‹è¯•

```python
# backend/tests/test_billing.py

import pytest
from decimal import Decimal
from app.services.workflow.steps.billing import BillingStep
from app.services.orchestrator.context import WorkflowContext, Channel

@pytest.mark.asyncio
async def test_billing_non_stream(db_session, redis_client):
    """æµ‹è¯•éæµå¼è®¡è´¹"""
    # å‡†å¤‡æ•°æ®
    tenant_id = "test-tenant-123"
    quota = await create_test_quota(
        db_session,
        tenant_id=tenant_id,
        balance=Decimal("100.00"),
    )
    
    # åˆ›å»ºä¸Šä¸‹æ–‡
    ctx = WorkflowContext(
        channel=Channel.EXTERNAL,
        capability="chat",
        requested_model="gpt-3.5-turbo",
        db_session=db_session,
        tenant_id=tenant_id,
        trace_id="test-trace-123",
    )
    
    # è®¾ç½® token ç”¨é‡
    ctx.billing.input_tokens = 100
    ctx.billing.output_tokens = 200
    
    # è®¾ç½®å®šä»·
    ctx.set("routing", "pricing_config", {
        "input_per_1k": 0.001,
        "output_per_1k": 0.002,
        "currency": "USD",
    })
    
    # æ‰§è¡Œè®¡è´¹
    step = BillingStep()
    result = await step.execute(ctx)
    
    # éªŒè¯ç»“æœ
    assert result.status == StepStatus.SUCCESS
    assert ctx.billing.total_cost == 0.0005  # (100/1000)*0.001 + (200/1000)*0.002
    
    # éªŒè¯äº¤æ˜“è®°å½•
    transaction = await billing_repo.get_by_trace_id("test-trace-123")
    assert transaction.status == TransactionStatus.COMMITTED
    assert transaction.amount == Decimal("0.0005")
    
    # éªŒè¯é…é¢
    quota = await quota_repo.get_or_create(tenant_id)
    assert quota.balance == Decimal("99.9995")
    assert quota.daily_used == 1
    assert quota.monthly_used == 1


@pytest.mark.asyncio
async def test_billing_stream_pending(db_session, redis_client):
    """æµ‹è¯•æµå¼è®¡è´¹ï¼ˆåˆ›å»º PENDING äº¤æ˜“ï¼‰"""
    # å‡†å¤‡æ•°æ®
    tenant_id = "test-tenant-123"
    quota = await create_test_quota(
        db_session,
        tenant_id=tenant_id,
        balance=Decimal("100.00"),
    )
    
    # åˆ›å»ºä¸Šä¸‹æ–‡
    ctx = WorkflowContext(
        channel=Channel.EXTERNAL,
        capability="chat",
        requested_model="gpt-3.5-turbo",
        db_session=db_session,
        tenant_id=tenant_id,
        trace_id="test-trace-123",
    )
    
    # è®¾ç½®æµå¼æ ‡å¿—
    ctx.set("upstream_call", "stream", True)
    
    # è®¾ç½®å®šä»·
    ctx.set("routing", "pricing_config", {
        "input_per_1k": 0.001,
        "output_per_1k": 0.002,
        "currency": "USD",
    })
    
    # æ‰§è¡Œè®¡è´¹
    step = BillingStep()
    result = await step.execute(ctx)
    
    # éªŒè¯ç»“æœ
    assert result.status == StepStatus.SUCCESS
    assert ctx.get("billing", "pending_transaction_id") is not None
    
    # éªŒè¯äº¤æ˜“è®°å½•
    transaction = await billing_repo.get_by_trace_id("test-trace-123")
    assert transaction.status == TransactionStatus.PENDING
    
    # éªŒè¯é…é¢æœªæ‰£å‡
    quota = await quota_repo.get_or_create(tenant_id)
    assert quota.balance == Decimal("100.00")
    assert quota.daily_used == 0
    assert quota.monthly_used == 0
```

### 3. BillingRepository å•å…ƒæµ‹è¯•

```python
# backend/tests/test_billing_repository.py

import pytest
from decimal import Decimal
from app.repositories.billing_repository import (
    BillingRepository,
    InsufficientBalanceError,
    DuplicateTransactionError,
)

@pytest.mark.asyncio
async def test_deduct_success(db_session, redis_client):
    """æµ‹è¯•æ‰£è´¹æˆåŠŸ"""
    # å‡†å¤‡æ•°æ®
    tenant_id = "test-tenant-123"
    quota = await create_test_quota(
        db_session,
        tenant_id=tenant_id,
        balance=Decimal("100.00"),
    )
    
    # æ‰§è¡Œæ‰£è´¹
    repo = BillingRepository(db_session)
    transaction = await repo.deduct(
        tenant_id=tenant_id,
        amount=Decimal("0.50"),
        trace_id="test-trace-123",
        input_tokens=100,
        output_tokens=200,
        input_price=Decimal("0.001"),
        output_price=Decimal("0.002"),
    )
    
    # éªŒè¯äº¤æ˜“
    assert transaction.status == TransactionStatus.COMMITTED
    assert transaction.amount == Decimal("0.50")
    assert transaction.balance_after == Decimal("99.50")
    
    # éªŒè¯é…é¢
    quota = await quota_repo.get_or_create(tenant_id)
    assert quota.balance == Decimal("99.50")
    assert quota.daily_used == 1
    assert quota.monthly_used == 1


@pytest.mark.asyncio
async def test_deduct_idempotency(db_session, redis_client):
    """æµ‹è¯•å¹‚ç­‰æ€§"""
    # å‡†å¤‡æ•°æ®
    tenant_id = "test-tenant-123"
    quota = await create_test_quota(
        db_session,
        tenant_id=tenant_id,
        balance=Decimal("100.00"),
    )
    
    repo = BillingRepository(db_session)
    
    # ç¬¬ä¸€æ¬¡æ‰£è´¹
    transaction1 = await repo.deduct(
        tenant_id=tenant_id,
        amount=Decimal("0.50"),
        trace_id="test-trace-123",
    )
    
    # ç¬¬äºŒæ¬¡æ‰£è´¹ï¼ˆç›¸åŒ trace_idï¼‰
    transaction2 = await repo.deduct(
        tenant_id=tenant_id,
        amount=Decimal("0.50"),
        trace_id="test-trace-123",
    )
    
    # éªŒè¯è¿”å›ç›¸åŒäº¤æ˜“
    assert transaction1.id == transaction2.id
    
    # éªŒè¯é…é¢åªæ‰£å‡ä¸€æ¬¡
    quota = await quota_repo.get_or_create(tenant_id)
    assert quota.balance == Decimal("99.50")
    assert quota.daily_used == 1
    assert quota.monthly_used == 1


@pytest.mark.asyncio
async def test_commit_pending_transaction(db_session, redis_client):
    """æµ‹è¯•æäº¤ PENDING äº¤æ˜“"""
    # å‡†å¤‡æ•°æ®
    tenant_id = "test-tenant-123"
    quota = await create_test_quota(
        db_session,
        tenant_id=tenant_id,
        balance=Decimal("100.00"),
    )
    
    repo = BillingRepository(db_session)
    
    # åˆ›å»º PENDING äº¤æ˜“
    pending_tx = await repo.create_pending_transaction(
        tenant_id=tenant_id,
        trace_id="test-trace-123",
        estimated_tokens=1000,
        pricing={"input_per_1k": 0.001, "output_per_1k": 0.002},
    )
    
    assert pending_tx.status == TransactionStatus.PENDING
    
    # æäº¤äº¤æ˜“
    committed_tx = await repo.commit_pending_transaction(
        trace_id="test-trace-123",
        input_tokens=100,
        output_tokens=200,
        input_price=Decimal("0.001"),
        output_price=Decimal("0.002"),
    )
    
    # éªŒè¯äº¤æ˜“
    assert committed_tx.id == pending_tx.id
    assert committed_tx.status == TransactionStatus.COMMITTED
    assert committed_tx.input_tokens == 100
    assert committed_tx.output_tokens == 200
    
    # éªŒè¯é…é¢
    quota = await quota_repo.get_or_create(tenant_id)
    assert quota.balance < Decimal("100.00")
    assert quota.daily_used == 1
    assert quota.monthly_used == 1
```



---

## ğŸš€ éƒ¨ç½²ä¸è¿ç»´

### 1. æ•°æ®åº“è¿ç§»è„šæœ¬

```python
# backend/migrations/versions/xxx_add_optimal_billing_schema.py

"""Add optimal billing schema

Revision ID: xxx
Revises: yyy
Create Date: 2026-01-10 12:00:00.000000

"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision = 'xxx'
down_revision = 'yyy'
branch_labels = None
depends_on = None


def upgrade():
    # 1. åˆ›å»º tenant_quota è¡¨
    op.create_table(
        'tenant_quota',
        sa.Column('id', postgresql.UUID(as_uuid=True), primary_key=True, server_default=sa.text('gen_random_uuid()')),
        sa.Column('tenant_id', postgresql.UUID(as_uuid=True), nullable=False, unique=True),
        sa.Column('balance', sa.DECIMAL(20, 6), nullable=False, server_default='0'),
        sa.Column('credit_limit', sa.DECIMAL(20, 6), nullable=False, server_default='0'),
        sa.Column('daily_quota', sa.Integer, nullable=False, server_default='1000'),
        sa.Column('daily_used', sa.Integer, nullable=False, server_default='0'),
        sa.Column('daily_reset_at', sa.Date, nullable=False),
        sa.Column('monthly_quota', sa.Integer, nullable=False, server_default='30000'),
        sa.Column('monthly_used', sa.Integer, nullable=False, server_default='0'),
        sa.Column('monthly_reset_at', sa.Date, nullable=False),
        sa.Column('rpm_limit', sa.Integer, nullable=True),
        sa.Column('tpm_limit', sa.Integer, nullable=True),
        sa.Column('created_at', sa.TIMESTAMP, nullable=False, server_default=sa.text('NOW()')),
        sa.Column('updated_at', sa.TIMESTAMP, nullable=False, server_default=sa.text('NOW()')),
        sa.Column('version', sa.Integer, nullable=False, server_default='1'),
    )
    
    op.create_index('idx_tenant_quota_tenant_id', 'tenant_quota', ['tenant_id'])
    op.create_index('idx_tenant_quota_daily_reset', 'tenant_quota', ['daily_reset_at'])
    op.create_index('idx_tenant_quota_monthly_reset', 'tenant_quota', ['monthly_reset_at'])
    
    # 2. åˆ›å»º billing_transaction è¡¨
    op.create_table(
        'billing_transaction',
        sa.Column('id', postgresql.UUID(as_uuid=True), primary_key=True, server_default=sa.text('gen_random_uuid()')),
        sa.Column('tenant_id', postgresql.UUID(as_uuid=True), nullable=False),
        sa.Column('api_key_id', postgresql.UUID(as_uuid=True), nullable=True),
        sa.Column('trace_id', sa.String(255), nullable=False, unique=True),
        sa.Column('type', sa.String(50), nullable=False),
        sa.Column('status', sa.String(50), nullable=False),
        sa.Column('amount', sa.DECIMAL(20, 6), nullable=False),
        sa.Column('currency', sa.String(10), nullable=False, server_default='USD'),
        sa.Column('input_tokens', sa.Integer, nullable=False, server_default='0'),
        sa.Column('output_tokens', sa.Integer, nullable=False, server_default='0'),
        sa.Column('input_price', sa.DECIMAL(20, 6), nullable=True),
        sa.Column('output_price', sa.DECIMAL(20, 6), nullable=True),
        sa.Column('balance_before', sa.DECIMAL(20, 6), nullable=True),
        sa.Column('balance_after', sa.DECIMAL(20, 6), nullable=True),
        sa.Column('provider', sa.String(100), nullable=True),
        sa.Column('model', sa.String(255), nullable=True),
        sa.Column('preset_item_id', postgresql.UUID(as_uuid=True), nullable=True),
        sa.Column('reversed_by', postgresql.UUID(as_uuid=True), nullable=True),
        sa.Column('description', sa.Text, nullable=True),
        sa.Column('created_at', sa.TIMESTAMP, nullable=False, server_default=sa.text('NOW()')),
        sa.Column('updated_at', sa.TIMESTAMP, nullable=False, server_default=sa.text('NOW()')),
    )
    
    op.create_index('idx_billing_tenant_id', 'billing_transaction', ['tenant_id'])
    op.create_index('idx_billing_trace_id', 'billing_transaction', ['trace_id'])
    op.create_index('idx_billing_api_key_id', 'billing_transaction', ['api_key_id'])
    op.create_index('idx_billing_status', 'billing_transaction', ['status'])
    op.create_index('idx_billing_created_at', 'billing_transaction', ['created_at'])
    op.create_index('idx_billing_tenant_created', 'billing_transaction', ['tenant_id', 'created_at'])
    
    # 3. åˆ›å»º api_key_quota è¡¨
    op.create_table(
        'api_key_quota',
        sa.Column('id', postgresql.UUID(as_uuid=True), primary_key=True, server_default=sa.text('gen_random_uuid()')),
        sa.Column('api_key_id', postgresql.UUID(as_uuid=True), nullable=False),
        sa.Column('quota_type', sa.String(50), nullable=False),
        sa.Column('total_quota', sa.BigInteger, nullable=False),
        sa.Column('used_quota', sa.BigInteger, nullable=False, server_default='0'),
        sa.Column('reset_period', sa.String(50), nullable=True),
        sa.Column('reset_at', sa.TIMESTAMP, nullable=True),
        sa.Column('created_at', sa.TIMESTAMP, nullable=False, server_default=sa.text('NOW()')),
        sa.Column('updated_at', sa.TIMESTAMP, nullable=False, server_default=sa.text('NOW()')),
    )
    
    op.create_unique_constraint('uq_api_key_quota_key_type', 'api_key_quota', ['api_key_id', 'quota_type'])
    op.create_index('idx_api_key_quota_key_id', 'api_key_quota', ['api_key_id'])
    op.create_index('idx_api_key_quota_reset_at', 'api_key_quota', ['reset_at'])


def downgrade():
    op.drop_table('api_key_quota')
    op.drop_table('billing_transaction')
    op.drop_table('tenant_quota')
```

### 2. Redis Lua è„šæœ¬æ–‡ä»¶

åˆ›å»ºç›®å½•å’Œè„šæœ¬æ–‡ä»¶ï¼š

```bash
mkdir -p backend/app/core/redis_scripts
```

**quota_check.lua**:
```lua
-- è§ä¸»æ–‡æ¡£ä¸­çš„å®Œæ•´è„šæœ¬
```

**quota_deduct.lua**:
```lua
-- è§ä¸»æ–‡æ¡£ä¸­çš„å®Œæ•´è„šæœ¬
```

### 3. ç¯å¢ƒå˜é‡é…ç½®

```bash
# backend/.env

# Redis é…ç½®
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0
REDIS_PASSWORD=

# æ•°æ®åº“é…ç½®
DATABASE_URL=postgresql+asyncpg://user:pass@localhost:5432/apiproxy

# è®¡è´¹é…ç½®
BILLING_BLOCK_ON_INSUFFICIENT=true  # ä½™é¢ä¸è¶³æ—¶æ˜¯å¦é˜»å¡è¯·æ±‚
BILLING_ALLOW_NEGATIVE=false  # æ˜¯å¦å…è®¸è´Ÿä½™é¢ï¼ˆéæµå¼ï¼‰
BILLING_STREAM_ALLOW_NEGATIVE=true  # æ˜¯å¦å…è®¸è´Ÿä½™é¢ï¼ˆæµå¼ï¼‰

# ç›‘æ§é…ç½®
PROMETHEUS_ENABLED=true
PROMETHEUS_PORT=9090
```

### 4. å¯åŠ¨è„šæœ¬

```bash
#!/bin/bash
# backend/scripts/start.sh

set -e

echo "Starting API Gateway..."

# 1. æ£€æŸ¥ç¯å¢ƒå˜é‡
if [ ! -f .env ]; then
    echo "Error: .env file not found"
    exit 1
fi

# 2. åŠ è½½ç¯å¢ƒå˜é‡
source .env

# 3. æ£€æŸ¥ Redis è¿æ¥
echo "Checking Redis connection..."
redis-cli -h $REDIS_HOST -p $REDIS_PORT ping || {
    echo "Error: Redis not available"
    exit 1
}

# 4. æ£€æŸ¥æ•°æ®åº“è¿æ¥
echo "Checking database connection..."
psql $DATABASE_URL -c "SELECT 1" || {
    echo "Error: Database not available"
    exit 1
}

# 5. è¿è¡Œæ•°æ®åº“è¿ç§»
echo "Running database migrations..."
alembic upgrade head

# 6. é¢„åŠ è½½ Redis Lua è„šæœ¬
echo "Preloading Redis Lua scripts..."
python -c "
from app.core.cache import cache
import asyncio
asyncio.run(cache.preload_scripts())
"

# 7. å¯åŠ¨åº”ç”¨
echo "Starting application..."
uvicorn main:app --host 0.0.0.0 --port 8000 --workers 4
```

### 5. å¥åº·æ£€æŸ¥ç«¯ç‚¹

```python
# backend/app/api/health.py

from fastapi import APIRouter, Depends
from sqlalchemy.ext.asyncio import AsyncSession

from app.core.database import get_db
from app.core.cache import cache

router = APIRouter(tags=["Health"])

@router.get("/health")
async def health_check(db: AsyncSession = Depends(get_db)):
    """å¥åº·æ£€æŸ¥"""
    checks = {
        "status": "healthy",
        "database": "unknown",
        "redis": "unknown",
        "lua_scripts": "unknown",
    }
    
    # æ£€æŸ¥æ•°æ®åº“
    try:
        await db.execute("SELECT 1")
        checks["database"] = "healthy"
    except Exception as e:
        checks["database"] = f"unhealthy: {e}"
        checks["status"] = "unhealthy"
    
    # æ£€æŸ¥ Redis
    try:
        redis_client = getattr(cache, "_redis", None)
        if redis_client:
            await redis_client.ping()
            checks["redis"] = "healthy"
        else:
            checks["redis"] = "not configured"
    except Exception as e:
        checks["redis"] = f"unhealthy: {e}"
        checks["status"] = "degraded"
    
    # æ£€æŸ¥ Lua è„šæœ¬
    try:
        script_shas = cache._script_shas
        if "quota_check" in script_shas and "quota_deduct" in script_shas:
            checks["lua_scripts"] = "loaded"
        else:
            checks["lua_scripts"] = "not loaded"
            checks["status"] = "degraded"
    except Exception as e:
        checks["lua_scripts"] = f"error: {e}"
    
    return checks


@router.get("/health/ready")
async def readiness_check(db: AsyncSession = Depends(get_db)):
    """å°±ç»ªæ£€æŸ¥ï¼ˆç”¨äº K8sï¼‰"""
    try:
        await db.execute("SELECT 1")
        redis_client = getattr(cache, "_redis", None)
        if redis_client:
            await redis_client.ping()
        return {"status": "ready"}
    except Exception as e:
        return {"status": "not ready", "error": str(e)}, 503


@router.get("/health/live")
async def liveness_check():
    """å­˜æ´»æ£€æŸ¥ï¼ˆç”¨äº K8sï¼‰"""
    return {"status": "alive"}
```

---

## ğŸ“Š ç›‘æ§ä¸å‘Šè­¦

### 1. Grafana Dashboard é…ç½®

```json
{
  "dashboard": {
    "title": "API Gateway - Billing & Quota",
    "panels": [
      {
        "title": "é…é¢æ£€æŸ¥æˆåŠŸç‡",
        "targets": [
          {
            "expr": "rate(quota_check_passed_total[5m]) / (rate(quota_check_passed_total[5m]) + rate(quota_check_failed_total[5m]))"
          }
        ]
      },
      {
        "title": "è®¡è´¹æˆåŠŸç‡",
        "targets": [
          {
            "expr": "rate(billing_deduct_success_total[5m]) / (rate(billing_deduct_success_total[5m]) + rate(billing_deduct_failure_total[5m]))"
          }
        ]
      },
      {
        "title": "æµå¼ Token è®¡ç®—æ–¹å¼åˆ†å¸ƒ",
        "targets": [
          {
            "expr": "sum by (method) (rate(stream_token_calculation_total[5m]))"
          }
        ]
      },
      {
        "title": "Redis ä¸ DB é…é¢å·®å¼‚",
        "targets": [
          {
            "expr": "quota_redis_db_diff"
          }
        ]
      },
      {
        "title": "è®¡è´¹ P99 å»¶è¿Ÿ",
        "targets": [
          {
            "expr": "histogram_quantile(0.99, rate(billing_duration_seconds_bucket[5m]))"
          }
        ]
      }
    ]
  }
}
```

### 2. AlertManager å‘Šè­¦è§„åˆ™

```yaml
# alertmanager/rules/billing.yml

groups:
  - name: billing
    interval: 30s
    rules:
      - alert: QuotaCheckFailureRateHigh
        expr: rate(quota_check_failed_total[5m]) > 0.05
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "é…é¢æ£€æŸ¥å¤±è´¥ç‡è¿‡é«˜"
          description: "é…é¢æ£€æŸ¥å¤±è´¥ç‡è¶…è¿‡ 5%"
      
      - alert: BillingFailureRateHigh
        expr: rate(billing_deduct_failure_total[5m]) > 0.01
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "è®¡è´¹å¤±è´¥ç‡è¿‡é«˜"
          description: "è®¡è´¹å¤±è´¥ç‡è¶…è¿‡ 1%"
      
      - alert: QuotaRedisDbDiffHigh
        expr: quota_redis_db_diff > 0.01
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "Redis ä¸ DB é…é¢å·®å¼‚è¿‡å¤§"
          description: "Redis ä¸ DB é…é¢å·®å¼‚è¶…è¿‡ 0.01"
      
      - alert: StreamTokenAccuracyLow
        expr: histogram_quantile(0.50, rate(stream_token_accuracy_percent_bucket[10m])) < 0.99
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "æµå¼ Token è®¡ç®—å‡†ç¡®ç‡ä½"
          description: "æµå¼ Token è®¡ç®—å‡†ç¡®ç‡ä½äº 99%"
      
      - alert: BillingLatencyHigh
        expr: histogram_quantile(0.99, rate(billing_duration_seconds_bucket[5m])) > 0.1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "è®¡è´¹å»¶è¿Ÿè¿‡é«˜"
          description: "è®¡è´¹ P99 å»¶è¿Ÿè¶…è¿‡ 100ms"
```

---

## âœ… æ€»ç»“

Part 3 è¡¥å……äº†ä»¥ä¸‹å†…å®¹ï¼š

1. âœ… **æµå¼è®¡è´¹å›è°ƒå®ç°** - æäº¤ PENDING äº¤æ˜“ï¼Œä½¿ç”¨ tiktoken ç²¾ç¡®è®¡ç®—
2. âœ… **StreamTokenAccumulator å¢å¼º** - ä¸‰çº§ä¼˜å…ˆçº§è®¡ç®—ï¼ˆusage > tiktoken > ä¼°ç®—ï¼‰
3. âœ… **é…ç½®æ–‡ä»¶** - Redis Lua è„šæœ¬åŠ è½½å™¨ã€ç¼“å­˜é”®å®šä¹‰ã€ç›‘æ§æŒ‡æ ‡å®šä¹‰
4. âœ… **å®Œæ•´æµ‹è¯•ç”¨ä¾‹** - QuotaCheckStepã€BillingStepã€BillingRepository å•å…ƒæµ‹è¯•
5. âœ… **éƒ¨ç½²ä¸è¿ç»´** - æ•°æ®åº“è¿ç§»è„šæœ¬ã€å¯åŠ¨è„šæœ¬ã€å¥åº·æ£€æŸ¥ç«¯ç‚¹
6. âœ… **ç›‘æ§ä¸å‘Šè­¦** - Grafana Dashboardã€AlertManager å‘Šè­¦è§„åˆ™

ç°åœ¨ä¸‰ä¸ªæ–‡æ¡£å·²ç»å®Œæ•´ï¼Œæ¶µç›–äº†ä»é›¶å¼€å§‹å®æ–½æœ€ä¼˜æ–¹æ¡ˆçš„æ‰€æœ‰ç»†èŠ‚ï¼
