# æ–‡ç”Ÿè§†é¢‘ (Text-to-Video) æ¥å…¥æ–¹æ¡ˆ

## ä¸€ã€API æ–‡æ¡£æ‘˜è¦

### 1. OpenAI Sora API

**æ¨¡å‹ç‰ˆæœ¬**:
- `sora-2` - åŸºç¡€ç‰ˆæœ¬
- `sora-2-pro` - ä¸“ä¸šç‰ˆï¼Œæ›´é«˜è´¨é‡

**API ç«¯ç‚¹**: `POST https://api.openai.com/v1/videos`

**æ”¯æŒçš„ç”Ÿæˆæ¨¡å¼**:
| æ¨¡å¼ | è¯´æ˜ |
|------|------|
| Text-to-Video | æ–‡æœ¬æè¿°ç”Ÿæˆè§†é¢‘ |
| Image-to-Video | å›¾ç‰‡ + æ–‡æœ¬ç”Ÿæˆè§†é¢‘ |
| Video Remix | åŸºäºç°æœ‰è§†é¢‘ç”Ÿæˆæ–°è§†é¢‘ |
| Video Extension | è§†é¢‘å»¶é•¿ |

**è¯·æ±‚å‚æ•°**:

```typescript
interface SoraGenerateRequest {
  // å¿…å¡«å‚æ•°
  model: 'sora-2' | 'sora-2-pro';
  prompt: string;                    // è§†é¢‘æè¿°ï¼Œæœ€å¤§ 2000 å­—ç¬¦

  // å¯é€‰å‚æ•°
  aspect_ratio?: '16:9' | '9:16' | '1:1';  // å®½é«˜æ¯”ï¼Œé»˜è®¤ 16:9
  duration?: 5 | 10 | 15 | 20 | 25;       // æ—¶é•¿ï¼ˆç§’ï¼‰ï¼ŒPro æœ€é•¿ 25s
  resolution?: '480p' | '720p' | '1080p'; // åˆ†è¾¨ç‡ï¼Œé»˜è®¤ 720p
  quality?: 'standard' | 'high';          // è´¨é‡ç­‰çº§

  // Image-to-Video æ¨¡å¼
  image_url?: string;                // èµ·å§‹å¸§å›¾ç‰‡ URL
  image_urls?: string[];             // å¤šå¼ å‚è€ƒå›¾ç‰‡

  // é«˜çº§é€‰é¡¹
  style?: string;                    // é£æ ¼æç¤º
  callback_url?: string;             // ç”Ÿæˆå®Œæˆå›è°ƒ URL
  remove_watermark?: boolean;        // ç§»é™¤æ°´å°ï¼ˆéœ€è¦ä»˜è´¹ï¼‰
}
```

**å“åº”ç»“æ„**:

```typescript
// åˆ›å»ºä»»åŠ¡å“åº”
interface SoraCreateResponse {
  id: string;                        // ç”Ÿæˆä»»åŠ¡ ID
  status: 'queued' | 'generating' | 'completed' | 'failed';
  created_at: string;
}

// æŸ¥è¯¢ç»“æœå“åº”
interface SoraResultResponse {
  id: string;
  status: 'queued' | 'generating' | 'completed' | 'failed';
  video_url?: string;                // è§†é¢‘ä¸‹è½½ URL
  thumbnail_url?: string;            // ç¼©ç•¥å›¾ URL
  duration?: number;                 // å®é™…æ—¶é•¿
  error?: {
    code: string;
    message: string;
  };
}
```

**API è°ƒç”¨æµç¨‹**:
```
1. POST /v1/videos                 â†’ åˆ›å»ºç”Ÿæˆä»»åŠ¡ï¼Œè¿”å› video_id
2. GET  /v1/videos/{video_id}      â†’ è½®è¯¢æŸ¥è¯¢çŠ¶æ€
3. çŠ¶æ€ä¸º completed æ—¶ï¼š
   - GET /v1/videos/{video_id}/content â†’ ä¸‹è½½ MP4ï¼ˆæˆ–ç”¨ variant ä¸‹è½½ thumbnail/spritesheetï¼‰
```

**å®šä»·** (ChatGPT Plus/Pro):
- Plus: 50 ä¸ªç”Ÿæˆé¢åº¦/æœˆï¼Œ720pï¼Œæœ€é•¿ 5s
- Pro: 500 ä¸ªç”Ÿæˆé¢åº¦/æœˆï¼Œ1080pï¼Œæœ€é•¿ 20s
- API å®šä»·: ~$0.01-0.05/ç§’è§†é¢‘

---

### 2. Google Veo API (Vertex AI)

**æ¨¡å‹ç‰ˆæœ¬**:
- `veo-2` - åŸºç¡€ç‰ˆæœ¬
- `veo-3-generate-preview` - é«˜è´¨é‡ç‰ˆæœ¬
- `veo-3-fast-preview` - å¿«é€Ÿç‰ˆæœ¬ï¼ˆä½å»¶è¿Ÿï¼‰
- `veo-3.1-generate-preview` - æœ€æ–°ç‰ˆæœ¬ï¼Œæ”¯æŒéŸ³é¢‘

**API ç«¯ç‚¹**: Vertex AI `generateVideos` æ–¹æ³•

**æ”¯æŒçš„ç”Ÿæˆæ¨¡å¼**:
| æ¨¡å¼ | è¯´æ˜ |
|------|------|
| Text-to-Video | æ–‡æœ¬æè¿°ç”Ÿæˆè§†é¢‘ |
| Image-to-Video | å•å¼ å›¾ç‰‡ç”Ÿæˆè§†é¢‘ |
| Frame Interpolation | é¦–å°¾å¸§æ’å€¼ç”Ÿæˆè§†é¢‘ |
| Video Extension | è§†é¢‘å»¶é•¿ |

**è¯·æ±‚å‚æ•°**:

```python
# Python SDK ç¤ºä¾‹
from google.genai import types

config = types.GenerateVideosConfig(
    # åŸºç¡€å‚æ•°
    number_of_videos=1,              # ç”Ÿæˆæ•°é‡ (1-4)
    duration_seconds=5,              # æ—¶é•¿: 4, 5, 6, 7, 8 ç§’

    # è§†é¢‘è§„æ ¼
    aspect_ratio='16:9',             # '16:9', '9:16', '1:1'
    resolution='720p',               # '720p', '1080p'

    # å¢å¼ºé€‰é¡¹
    enhance_prompt=True,             # è‡ªåŠ¨ä¼˜åŒ–æç¤ºè¯

    # Veo 3.1 ä¸“å±
    generate_audio=True,             # ç”Ÿæˆé…å¥—éŸ³é¢‘

    # å¸§æ§åˆ¶ (Image-to-Video)
    # first_frame=image,             # é¦–å¸§å›¾ç‰‡
    # last_frame=image,              # å°¾å¸§å›¾ç‰‡ (ç”¨äºæ’å€¼)
)

operation = client.models.generate_videos(
    model='veo-3.1-generate-preview',
    prompt='A neon hologram of a cat driving at top speed',
    image=first_frame_image,         # å¯é€‰ï¼šèµ·å§‹å¸§
    config=config,
)
```

**TypeScript/JavaScript å‚æ•°**:

```typescript
interface VeoGenerateRequest {
  // å¿…å¡«
  model: 'veo-2' | 'veo-3-generate-preview' | 'veo-3-fast-preview' | 'veo-3.1-generate-preview';
  prompt: string;

  // å¯é€‰
  config: {
    numberOfVideos?: number;         // 1-4
    durationSeconds?: 4 | 5 | 6 | 7 | 8;
    aspectRatio?: '16:9' | '9:16' | '1:1';
    resolution?: '720p' | '1080p';
    enhancePrompt?: boolean;
    generateAudio?: boolean;         // Veo 3.1+
  };

  // Image-to-Video
  image?: {
    imageBytes?: string;             // Base64 å›¾ç‰‡æ•°æ®
    mimeType?: string;               // 'image/png' | 'image/jpeg'
    uri?: string;                    // GCS URI
  };

  // Frame Interpolation (Veo 3.1)
  lastFrame?: {
    imageBytes?: string;
    mimeType?: string;
  };
}
```

**å“åº”ç»“æ„**:

```typescript
interface VeoOperationResponse {
  name: string;                      // æ“ä½œ ID
  done: boolean;                     // æ˜¯å¦å®Œæˆ

  // å®Œæˆå
  response?: {
    generatedVideos: Array<{
      video: {
        uri: string;                 // GCS è§†é¢‘ URI
        mimeType: string;
      };
    }>;
  };

  // é”™è¯¯ä¿¡æ¯
  error?: {
    code: number;
    message: string;
  };
}
```

**API è°ƒç”¨æµç¨‹**:
```
1. generateVideos()              â†’ åˆ›å»ºç”Ÿæˆä»»åŠ¡ï¼Œè¿”å› operation
2. operations.get(operation)     â†’ è½®è¯¢æŸ¥è¯¢çŠ¶æ€
3. operation.done = true æ—¶è·å–è§†é¢‘ URI
```

**å®šä»·** (Vertex AI):
- Veo 2: ~$0.35/ç§’è§†é¢‘
- Veo 3: ~$0.50/ç§’è§†é¢‘
- Veo 3.1: ~$0.60/ç§’è§†é¢‘

---

## äºŒã€API å¯¹æ¯”æ€»ç»“

| ç‰¹æ€§ | OpenAI Sora 2 | Google Veo 3.1 |
|------|---------------|----------------|
| æœ€å¤§æ—¶é•¿ | 25ç§’ (Pro) | 8ç§’ |
| åˆ†è¾¨ç‡ | 1080p | 1080p |
| å®½é«˜æ¯” | 16:9, 9:16, 1:1 | 16:9, 9:16, 1:1 |
| éŸ³é¢‘ç”Ÿæˆ | Sora 2 æ”¯æŒ | âœ… åŸç”Ÿæ”¯æŒ |
| Image-to-Video | âœ… | âœ… |
| å¸§æ’å€¼ | âŒ | âœ… (é¦–å°¾å¸§) |
| è§†é¢‘å»¶é•¿ | âœ… | âœ… |
| API å¯ç”¨æ€§ | ChatGPT Plus/Pro + API | Vertex AI |
| ç”Ÿæˆé€Ÿåº¦ | 30s-2min | 1-3min |
| æ°´å° | æœ‰ (å¯ç§»é™¤) | æœ‰ SynthID |

---

## äºŒç‚¹äº”ã€è·¨å‚å•†ç»Ÿä¸€å‚æ•°ç”»åƒï¼ˆå‚è€ƒ TTS çš„åˆ†å±‚åšæ³•ï¼‰

ç›®æ ‡ï¼šåœ¨ä¸è®©å‚å•† DTO æ³„éœ²åˆ°ä¸šåŠ¡å±‚çš„å‰æä¸‹ï¼Œå®šä¹‰ä¸€å¥—â€œå°½å¯èƒ½è¦†ç›–ä¸»æµè§†é¢‘ç”Ÿæˆâ€çš„ç»Ÿä¸€è¯­ä¹‰å‚æ•°é›†åˆï¼Œå¹¶å…è®¸é€šè¿‡å°‘é‡ `extra_body` åšå·®å¼‚åŒ–è¡¥é½ã€‚

### 2.5.1 ç°çŠ¶ï¼šç½‘å…³å·²è½åœ°çš„ç»Ÿä¸€å­—æ®µï¼ˆæœ€å°ç¨³å®šæ ¸ï¼‰

å½“å‰ç½‘å…³ä¾§å·²å®ç°çš„â€œä¼šè¯å†…è§†é¢‘ç”Ÿæˆâ€å…¥å£ï¼ˆJWTï¼‰å¯¹å¤–å®é™…å¯ç”¨å­—æ®µç­‰ä»·äºï¼š
- `model`ï¼šé€»è¾‘æ¨¡å‹ IDï¼ˆç½‘å…³é€‰è·¯ï¼‰
- `prompt`ï¼šæ–‡æœ¬æç¤ºè¯
- `size`ï¼šåˆ†è¾¨ç‡ï¼ˆå¦‚ `1280x720`ï¼‰
- `seconds`ï¼šè§†é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰
- `extra_body`ï¼šä¿ç•™æ‰©å±•å­—æ®µå®¹å™¨ï¼ˆå»ºè®®ç»“æ„ `{ openai: {...}, google: {...} }`ï¼‰

è¿™å¥—å­—æ®µèƒ½è¦†ç›–ï¼š
- OpenAI Soraï¼š`POST /v1/videos`ï¼ˆmultipartï¼š`prompt/model/size/seconds`ï¼‰
- Gemini Veoï¼ˆGemini APIï¼‰ï¼š`...:predictLongRunning`ï¼ˆJSONï¼š`instances[].prompt + parameters`ï¼‰

### 2.5.2 å»ºè®®ï¼šä¸‰å±‚å‚æ•°æ¨¡å‹ï¼ˆCore / Standard / Advancedï¼‰

å‚ç…§ `docs/tts-parameter-catalog.md` çš„åšæ³•ï¼Œå»ºè®®æŠŠè§†é¢‘ç”Ÿæˆç»Ÿä¸€è¯­ä¹‰æ‹†æˆä¸‰å±‚ï¼š

1) **Coreï¼ˆå¿…é¡»ï¼‰**ï¼šä»»ä½•å‚å•†éƒ½åº”èƒ½è½åœ°
- `prompt`
- `model`
- `seconds`
- `size`ï¼ˆæˆ– `aspect_ratio + resolution`ï¼ŒäºŒé€‰ä¸€ï¼Œæ¨èä¿ç•™ `size` ä½œä¸ºç½‘å…³â€œçœŸå®è½åœ°å­—æ®µâ€ï¼‰

2) **Standardï¼ˆæ¨èï¼‰**ï¼šä¸»æµå¹³å°æ™®éå…·å¤‡ã€ä¸”è¯­ä¹‰å¯å½’ä¸€
- `aspect_ratio`ï¼š`16:9|9:16|1:1|4:3|3:4|21:9`ï¼ˆå¯ç”± `size` æ¨å¯¼ï¼›æˆ–åå‘æ˜ å°„åˆ° `size`ï¼‰
- `resolution`ï¼š`480p|720p|1080p|2k|4k`ï¼ˆä¸åŒå‚å•†æ”¯æŒä¸åŒï¼Œç½‘å…³è´Ÿè´£é™çº§/æ˜ å°„ï¼‰
- `negative_prompt`ï¼šè´Ÿå‘æç¤ºè¯ï¼ˆVeo/Pika/å¤šæ•°å¹³å°æ”¯æŒï¼‰
- `seed`ï¼šéšæœºç§å­ï¼ˆRunway/è±†åŒ…ç­‰å¸¸è§ï¼›ä¸ä¿è¯è·¨å‚å•†å®Œå…¨å¯å¤ç°ï¼‰
- `fps`ï¼šå¸§ç‡ï¼ˆéƒ¨åˆ†å¹³å°æ”¯æŒï¼Œå¦‚è±†åŒ…/Pikaï¼‰
- `num_outputs`ï¼šç”Ÿæˆæ•°é‡ï¼ˆVeo å¸¸è§ `numberOfVideos`ï¼‰
- `generate_audio`ï¼šæ˜¯å¦ç”ŸæˆéŸ³é¢‘ï¼ˆVeo 3.1+ï¼‰

3) **Advancedï¼ˆå¯é€‰ï¼‰**ï¼šè¦†ç›–å·®å¼‚è¾ƒå¤§çš„â€œæ§åˆ¶/å‚è€ƒ/ç¼–è¾‘â€èƒ½åŠ›
- `input_image_url` / `input_image_id`ï¼šå›¾ç”Ÿè§†é¢‘ï¼ˆé¦–å¸§/å‚è€ƒå›¾ï¼‰
- `input_images`ï¼šå¤šå‚è€ƒå›¾ï¼ˆSora å‚è€ƒå›¾ã€Veo up to Nã€Pika ingredient ç­‰ï¼‰
- `last_frame_url`ï¼šé¦–å°¾å¸§/æ’å€¼
- `remix_video_id`ï¼šremixï¼ˆåŸºäºå·²ç”Ÿæˆè§†é¢‘åšå±€éƒ¨ä¿®æ”¹ï¼‰
- `extend_video_id`ï¼šå»¶é•¿ï¼ˆé€šå¸¸è¦æ±‚â€œå¿…é¡»æ˜¯åŒå¹³å°ç”Ÿæˆçš„è§†é¢‘â€ï¼‰
- `style` / `camera_control` / `motion_strength` / `guidance_scale`ï¼šä¸åŒå¹³å°å‚æ•°åå·®å¼‚å¤§ï¼Œä¼˜å…ˆèµ° `extra_body` åˆ†æµ
- `watermark`ï¼šæ°´å°å¼€å…³ï¼ˆRunway/éƒ¨åˆ†å¹³å°ï¼‰

å»ºè®®çš„ç»Ÿä¸€è¯·æ±‚ï¼ˆç¤ºæ„ï¼Œä¸ä»£è¡¨å·²å…¨éƒ¨è½åœ°ï¼‰ï¼š
```ts
// ç»Ÿä¸€å…¥å£ï¼šSpeechRequest çš„è§†é¢‘ç‰ˆæœ¬ï¼ˆå»ºè®®ï¼‰
export interface VideoRequest {
  // Core
  model: string
  prompt: string
  size?: string            // "1280x720"
  seconds?: number         // 4/6/8/...

  // Standardï¼ˆå¯é€‰ï¼‰
  aspect_ratio?: "16:9" | "9:16" | "1:1" | "4:3" | "3:4" | "21:9"
  resolution?: "480p" | "720p" | "1080p" | "2k" | "4k"
  negative_prompt?: string
  seed?: number
  fps?: number
  num_outputs?: number
  generate_audio?: boolean

  // Advancedï¼ˆå¯é€‰ï¼‰
  input_image_url?: string
  input_images?: string[]
  last_frame_url?: string
  remix_video_id?: string
  extend_video_id?: string
  style?: string
  watermark?: boolean

  // å‚å•†æ‰©å±•ï¼ˆæ¨èä¿ç•™ï¼Œé¿å…ä¸ºæ¯ä¸ªâ€œæ€ªå­—æ®µâ€éƒ½æ”¹ schemaï¼‰
  extra_body?: { openai?: Record<string, unknown>; google?: Record<string, unknown> }
}
```

### 2.5.3 ç»Ÿä¸€å­—æ®µä¸ä¸»æµå¹³å°æ˜ å°„å»ºè®®ï¼ˆæ‘˜è¦ï¼‰

> è§„åˆ™ï¼šç½‘å…³å†…éƒ¨å°½é‡åªä¾èµ–ç»Ÿä¸€å­—æ®µï¼›é‡åˆ°â€œè¯­ä¹‰æ— æ³•å½’ä¸€/å­—æ®µç»“æ„è¿‡æ·±â€çš„ï¼Œæ”¶æ•›è¿› `extra_body.<vendor>`ï¼Œå¹¶åœ¨é€‰è·¯å±‚åšèƒ½åŠ›è¿‡æ»¤ï¼ˆç±»ä¼¼ TTS çš„ `requires_reference_audio` æ€è·¯ï¼‰ã€‚

| ç»Ÿä¸€è¯­ä¹‰ | OpenAI Sora | Gemini Veo | Runway | Pika | è±†åŒ… |
|---|---|---|---|---|---|
| `prompt` | `prompt` | `instances[].prompt` | `promptText` | `promptText` | `promptText` |
| `seconds` | `seconds` | `durationSeconds` | `duration` | `options.*` | `duration` |
| `size` | `size` | `parameters.resolution + aspectRatio`ï¼ˆæ˜ å°„ï¼‰ | `ratio`ï¼ˆæ˜ å°„ï¼‰ | `options.aspectRatio + frameRate`ï¼ˆæ˜ å°„ï¼‰ | `resolution + ratio`ï¼ˆæ˜ å°„ï¼‰ |
| `negative_prompt` | `extra_body.openai`ï¼ˆè‹¥æ”¯æŒï¼‰ | `parameters.negativePrompt` | - | `options.parameters.negativePrompt` | - |
| `seed` | `extra_body.openai`ï¼ˆè‹¥æ”¯æŒï¼‰ | `extra_body.google`ï¼ˆè‹¥æ”¯æŒï¼‰ | `seed` | - | `seed` |
| `generate_audio` | - | `generateAudio` | - | `pikaffect`ï¼ˆæ•ˆæœä¾§ï¼‰ | - |
| `input_image_url` | `input_reference`ï¼ˆfile/urlï¼‰ | `image` / `first_frame` | `promptImage` | `image` | `image` |
| `last_frame_url` | - | `lastFrame` | - | - | `image_tail` |
| `watermark` | - | - | `watermark` | - | `watermark` |

---

## ä¸‰ã€åŠŸèƒ½è®¾è®¡

### 3.1 ç”¨æˆ·äº¤äº’æµç¨‹

```
ç”¨æˆ·è§†è§’:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  è§†é¢‘ç”Ÿæˆé¢æ¿                                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ æç¤ºè¯: [ä¸€åªçŒ«åœ¨å¼¹é’¢ç´ï¼ŒèƒŒæ™¯æ˜¯æ˜Ÿç©º____________] [âœ¨ä¼˜åŒ–]     â”‚â”‚
â”‚  â”‚                                                             â”‚â”‚
â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚â”‚
â”‚  â”‚ â”‚ ğŸ“· ä¸Šä¼ å›¾ç‰‡  â”‚  â”‚ ğŸ¬ ä¸Šä¼ è§†é¢‘  â”‚  (å¯é€‰å‚è€ƒ)               â”‚â”‚
â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚â”‚
â”‚  â”‚                                                             â”‚â”‚
â”‚  â”‚ å‚æ•°è®¾ç½®:                                                    â”‚â”‚
â”‚  â”‚ â”œâ”€ æœåŠ¡å•†: [OpenAI Sora â–¼] [Google Veo â–¼]                  â”‚â”‚
â”‚  â”‚ â”œâ”€ æ—¶é•¿:   [5ç§’ â–¼]                                         â”‚â”‚
â”‚  â”‚ â”œâ”€ æ¯”ä¾‹:   [16:9 â–¼] [9:16] [1:1]                          â”‚â”‚
â”‚  â”‚ â”œâ”€ åˆ†è¾¨ç‡: [720p â–¼] [1080p]                                â”‚â”‚
â”‚  â”‚ â””â”€ éŸ³é¢‘:   [âœ“] ç”Ÿæˆé…å¥—éŸ³æ•ˆ                                 â”‚â”‚
â”‚  â”‚                                                             â”‚â”‚
â”‚  â”‚            [ğŸ¬ ç”Ÿæˆè§†é¢‘]                                     â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                                                  â”‚
â”‚  ç”ŸæˆçŠ¶æ€:                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ â³ æ­£åœ¨ç”Ÿæˆ... é¢„è®¡ 1-2 åˆ†é’Ÿ                                 â”‚â”‚
â”‚  â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 60%                                    â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                                                  â”‚
â”‚  ç”Ÿæˆç»“æœ:                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                    â”‚â”‚
â”‚  â”‚  â”‚                     â”‚                                    â”‚â”‚
â”‚  â”‚  â”‚    ğŸ¬ è§†é¢‘é¢„è§ˆ       â”‚  [â–¶ï¸ æ’­æ”¾] [â¬‡ï¸ ä¸‹è½½] [ğŸ”„ é‡æ–°ç”Ÿæˆ] â”‚â”‚
â”‚  â”‚  â”‚                     â”‚                                    â”‚â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                    â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.2 æ ¸å¿ƒåŠŸèƒ½

1. **æ–‡æœ¬ç”Ÿæˆè§†é¢‘** - è¾“å…¥æè¿°ï¼Œç”Ÿæˆè§†é¢‘
2. **å›¾ç‰‡ç”Ÿæˆè§†é¢‘** - ä¸Šä¼ å›¾ç‰‡ä½œä¸ºèµ·å§‹å¸§
3. **å‚æ•°é…ç½®** - æ—¶é•¿ã€æ¯”ä¾‹ã€åˆ†è¾¨ç‡ã€éŸ³é¢‘
4. **ç”ŸæˆçŠ¶æ€è¿½è¸ª** - å®æ—¶æ˜¾ç¤ºè¿›åº¦
5. **ç»“æœé¢„è§ˆä¸‹è½½** - æ’­æ”¾ã€ä¸‹è½½ç”Ÿæˆçš„è§†é¢‘
6. **å†å²è®°å½•** - ä¿å­˜ç”Ÿæˆå†å²

---

## å››ã€æŠ€æœ¯æ¶æ„

### 4.1 æ•´ä½“æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Frontend                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ VideoGenForm   â”‚  â”‚ VideoPreview   â”‚  â”‚ VideoHistory       â”‚  â”‚
â”‚  â”‚ Component      â”‚â”€â”€â”‚ Component      â”‚â”€â”€â”‚ Component          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚           â”‚                  â”‚                    â”‚               â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                              â”‚                                    â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚                    â”‚ Video Gen Service â”‚                         â”‚
â”‚                    â”‚ + WebSocket/SSE   â”‚                         â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Backend                                   â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚                    â”‚ /v1/video/generateâ”‚                         â”‚
â”‚                    â”‚ Video Router      â”‚                         â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â”‚                              â”‚                                    â”‚
â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚           â”‚                  â”‚                  â”‚                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚ OpenAI Sora     â”‚ â”‚ Google Veo    â”‚ â”‚ Task Queue    â”‚        â”‚
â”‚  â”‚ Provider        â”‚ â”‚ Provider      â”‚ â”‚ (Celery/Redis)â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                              â”‚                                    â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚                    â”‚ Storage Service   â”‚                         â”‚
â”‚                    â”‚ (S3/GCS/MinIO)    â”‚                         â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4.2 æ•°æ®æµ

```
1. ç”¨æˆ·æäº¤ç”Ÿæˆè¯·æ±‚
       â”‚
       â–¼
2. å‰ç«¯è°ƒç”¨ API
   POST /v1/video/generate
   {
     "prompt": "ä¸€åªçŒ«åœ¨å¼¹é’¢ç´",
     "provider": "openai",
     "duration": 5,
     "aspect_ratio": "16:9",
     "resolution": "720p",
     "image_url": "...",  // å¯é€‰
   }
       â”‚
       â–¼
3. åç«¯åˆ›å»ºå¼‚æ­¥ä»»åŠ¡
   - ä¿å­˜ä»»åŠ¡è®°å½•åˆ°æ•°æ®åº“
   - å°†ä»»åŠ¡åŠ å…¥é˜Ÿåˆ—
   - è¿”å› task_id
       â”‚
       â–¼
4. åå° Worker æ‰§è¡Œ
   - è°ƒç”¨ Sora/Veo API
   - è½®è¯¢ç­‰å¾…ç”Ÿæˆå®Œæˆ
   - ä¸‹è½½è§†é¢‘åˆ°å­˜å‚¨æœåŠ¡
   - æ›´æ–°ä»»åŠ¡çŠ¶æ€
       â”‚
       â–¼
5. å‰ç«¯è½®è¯¢/WebSocket è·å–çŠ¶æ€
   GET /v1/video/tasks/{task_id}
       â”‚
       â–¼
6. å®Œæˆåè¿”å›è§†é¢‘ URL
```

---

## äº”ã€åç«¯å®ç°

### 5.1 API è®¾è®¡

#### 5.1.1 åˆ›å»ºè§†é¢‘ç”Ÿæˆä»»åŠ¡

```
POST /v1/video/generate
```

**è¯·æ±‚ä½“**:
```typescript
interface VideoGenerateRequest {
  // å¿…å¡«
  prompt: string;                        // è§†é¢‘æè¿°
  provider: 'openai' | 'google';         // æœåŠ¡å•†

  // è§†é¢‘å‚æ•°
  duration?: number;                     // æ—¶é•¿(ç§’): 4-25
  aspect_ratio?: '16:9' | '9:16' | '1:1';
  resolution?: '720p' | '1080p';

  // å¯é€‰è¾“å…¥
  image_url?: string;                    // èµ·å§‹å¸§å›¾ç‰‡
  image_base64?: string;                 // æˆ– Base64 å›¾ç‰‡
  last_frame_url?: string;               // å°¾å¸§å›¾ç‰‡ (Veo æ’å€¼)

  // é«˜çº§é€‰é¡¹
  enhance_prompt?: boolean;              // ä¼˜åŒ–æç¤ºè¯
  generate_audio?: boolean;              // ç”ŸæˆéŸ³é¢‘ (Veo 3.1)
  style?: string;                        // é£æ ¼æç¤º

  // æ¨¡å‹é€‰æ‹©
  model?: string;                        // å…·ä½“æ¨¡å‹ç‰ˆæœ¬
}
```

**å“åº”**:
```typescript
interface VideoGenerateResponse {
  task_id: string;                       // ä»»åŠ¡ ID
  status: 'pending' | 'processing' | 'completed' | 'failed';
  created_at: string;
  estimated_time_seconds?: number;       // é¢„ä¼°å®Œæˆæ—¶é—´
}
```

#### 5.1.2 æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€

```
GET /v1/video/tasks/{task_id}
```

**å“åº”**:
```typescript
interface VideoTaskResponse {
  task_id: string;
  status: 'pending' | 'processing' | 'completed' | 'failed';
  progress?: number;                     // 0-100

  // å®Œæˆå
  video_url?: string;                    // è§†é¢‘ä¸‹è½½ URL
  thumbnail_url?: string;                // ç¼©ç•¥å›¾
  duration?: number;                     // å®é™…æ—¶é•¿

  // å¤±è´¥æ—¶
  error?: {
    code: string;
    message: string;
  };

  // å…ƒæ•°æ®
  prompt: string;
  provider: string;
  created_at: string;
  completed_at?: string;
}
```

#### 5.1.3 è·å–ç”Ÿæˆå†å²

```
GET /v1/video/history?limit=20&cursor=xxx
```

#### 5.1.4 å–æ¶ˆç”Ÿæˆä»»åŠ¡

```
DELETE /v1/video/tasks/{task_id}
```

### 5.2 æ•°æ®åº“æ¨¡å‹

```python
# backend/app/models/video_generation.py

from sqlalchemy import Column, String, Integer, DateTime, Text, Enum
from app.db.base import Base
import enum

class VideoTaskStatus(enum.Enum):
    PENDING = "pending"
    PROCESSING = "processing"
    COMPLETED = "completed"
    FAILED = "failed"
    CANCELLED = "cancelled"

class VideoGenerationTask(Base):
    __tablename__ = "video_generation_tasks"

    id = Column(String(36), primary_key=True)
    user_id = Column(String(36), nullable=False, index=True)

    # è¯·æ±‚å‚æ•°
    prompt = Column(Text, nullable=False)
    provider = Column(String(20), nullable=False)  # openai, google
    model = Column(String(50))
    duration = Column(Integer, default=5)
    aspect_ratio = Column(String(10), default="16:9")
    resolution = Column(String(10), default="720p")

    # è¾“å…¥èµ„æº
    input_image_url = Column(Text)
    last_frame_url = Column(Text)

    # é€‰é¡¹
    enhance_prompt = Column(Boolean, default=True)
    generate_audio = Column(Boolean, default=False)

    # çŠ¶æ€
    status = Column(Enum(VideoTaskStatus), default=VideoTaskStatus.PENDING)
    progress = Column(Integer, default=0)

    # å¤–éƒ¨ä»»åŠ¡ ID
    external_task_id = Column(String(100))

    # ç»“æœ
    video_url = Column(Text)
    thumbnail_url = Column(Text)
    actual_duration = Column(Integer)

    # é”™è¯¯ä¿¡æ¯
    error_code = Column(String(50))
    error_message = Column(Text)

    # æ—¶é—´æˆ³
    created_at = Column(DateTime, default=datetime.utcnow)
    started_at = Column(DateTime)
    completed_at = Column(DateTime)
```

### 5.3 Provider å®ç°

#### 5.3.1 åŸºç±»

```python
# backend/app/services/video/base.py

from abc import ABC, abstractmethod
from typing import Optional, AsyncIterator
from dataclasses import dataclass

@dataclass
class VideoGenerationResult:
    video_url: str
    thumbnail_url: Optional[str] = None
    duration: Optional[int] = None

@dataclass
class VideoGenerationStatus:
    status: str  # pending, processing, completed, failed
    progress: Optional[int] = None
    result: Optional[VideoGenerationResult] = None
    error: Optional[str] = None

class VideoProvider(ABC):
    """è§†é¢‘ç”Ÿæˆ Provider åŸºç±»"""

    @abstractmethod
    async def create_generation(
        self,
        prompt: str,
        duration: int = 5,
        aspect_ratio: str = "16:9",
        resolution: str = "720p",
        image_url: Optional[str] = None,
        **kwargs
    ) -> str:
        """åˆ›å»ºç”Ÿæˆä»»åŠ¡ï¼Œè¿”å›å¤–éƒ¨ä»»åŠ¡ ID"""
        pass

    @abstractmethod
    async def get_status(self, external_task_id: str) -> VideoGenerationStatus:
        """æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€"""
        pass

    @abstractmethod
    async def cancel(self, external_task_id: str) -> bool:
        """å–æ¶ˆä»»åŠ¡"""
        pass
```

#### 5.3.2 OpenAI Sora Provider

```python
# backend/app/services/video/openai_sora.py

from openai import AsyncOpenAI
from .base import VideoProvider, VideoGenerationStatus, VideoGenerationResult

class OpenAISoraProvider(VideoProvider):
    def __init__(self, api_key: str):
        self.client = AsyncOpenAI(api_key=api_key)
        self.default_model = "sora-2-pro"

    async def create_generation(
        self,
        prompt: str,
        duration: int = 5,
        aspect_ratio: str = "16:9",
        resolution: str = "720p",
        image_url: Optional[str] = None,
        **kwargs
    ) -> str:
        request_params = {
            "model": kwargs.get("model", self.default_model),
            "prompt": prompt,
            "duration": duration,
            "aspect_ratio": aspect_ratio,
            "resolution": resolution,
        }

        if image_url:
            request_params["image_url"] = image_url

        response = await self.client.video.generations.create(**request_params)
        return response.id

    async def get_status(self, external_task_id: str) -> VideoGenerationStatus:
        response = await self.client.video.generations.retrieve(external_task_id)

        if response.status == "completed":
            return VideoGenerationStatus(
                status="completed",
                progress=100,
                result=VideoGenerationResult(
                    video_url=response.video_url,
                    thumbnail_url=response.thumbnail_url,
                    duration=response.duration,
                )
            )
        elif response.status == "failed":
            return VideoGenerationStatus(
                status="failed",
                error=response.error.message if response.error else "Unknown error"
            )
        else:
            # queued, generating
            return VideoGenerationStatus(
                status="processing",
                progress=50 if response.status == "generating" else 10
            )

    async def cancel(self, external_task_id: str) -> bool:
        try:
            await self.client.video.generations.cancel(external_task_id)
            return True
        except Exception:
            return False
```

#### 5.3.3 Google Veo Provider

```python
# backend/app/services/video/google_veo.py

from google import genai
from google.genai import types
from .base import VideoProvider, VideoGenerationStatus, VideoGenerationResult

class GoogleVeoProvider(VideoProvider):
    def __init__(self, api_key: str = None, project_id: str = None):
        if project_id:
            # Vertex AI
            self.client = genai.Client(vertexai=True, project=project_id)
        else:
            # Google AI
            self.client = genai.Client(api_key=api_key)

        self.default_model = "veo-3.1-generate-preview"

    async def create_generation(
        self,
        prompt: str,
        duration: int = 5,
        aspect_ratio: str = "16:9",
        resolution: str = "720p",
        image_url: Optional[str] = None,
        last_frame_url: Optional[str] = None,
        generate_audio: bool = False,
        enhance_prompt: bool = True,
        **kwargs
    ) -> str:
        # æ„å»ºé…ç½®
        config = types.GenerateVideosConfig(
            number_of_videos=1,
            duration_seconds=min(duration, 8),  # Veo æœ€é•¿ 8 ç§’
            aspect_ratio=aspect_ratio,
            resolution=resolution,
            enhance_prompt=enhance_prompt,
        )

        # å¦‚æœæ˜¯ Veo 3.1ï¼Œæ”¯æŒéŸ³é¢‘
        if "3.1" in kwargs.get("model", self.default_model):
            config.generate_audio = generate_audio

        generation_params = {
            "model": kwargs.get("model", self.default_model),
            "prompt": prompt,
            "config": config,
        }

        # æ·»åŠ èµ·å§‹å¸§
        if image_url:
            image_data = await self._fetch_image(image_url)
            generation_params["image"] = types.Image(
                image_bytes=image_data,
                mime_type="image/png"
            )

        # æ·»åŠ ç»“æŸå¸§ï¼ˆå¸§æ’å€¼ï¼‰
        if last_frame_url:
            last_image_data = await self._fetch_image(last_frame_url)
            config.last_frame = types.Image(
                image_bytes=last_image_data,
                mime_type="image/png"
            )

        operation = self.client.models.generate_videos(**generation_params)
        return operation.name

    async def get_status(self, external_task_id: str) -> VideoGenerationStatus:
        operation = self.client.operations.get(name=external_task_id)

        if operation.done:
            if operation.error:
                return VideoGenerationStatus(
                    status="failed",
                    error=operation.error.message
                )

            video = operation.response.generated_videos[0].video
            return VideoGenerationStatus(
                status="completed",
                progress=100,
                result=VideoGenerationResult(
                    video_url=video.uri,
                )
            )
        else:
            return VideoGenerationStatus(
                status="processing",
                progress=50
            )

    async def cancel(self, external_task_id: str) -> bool:
        try:
            self.client.operations.cancel(name=external_task_id)
            return True
        except Exception:
            return False

    async def _fetch_image(self, url: str) -> bytes:
        import httpx
        async with httpx.AsyncClient() as client:
            response = await client.get(url)
            return response.content
```

### 5.4 å¼‚æ­¥ä»»åŠ¡å¤„ç†

```python
# backend/app/tasks/video_generation.py

from celery import shared_task
from app.services.video import get_video_provider
from app.models.video_generation import VideoGenerationTask, VideoTaskStatus
from app.db.session import SessionLocal
import asyncio
import time

@shared_task(bind=True, max_retries=3)
def process_video_generation(self, task_id: str):
    """å¤„ç†è§†é¢‘ç”Ÿæˆä»»åŠ¡"""
    db = SessionLocal()

    try:
        task = db.query(VideoGenerationTask).filter_by(id=task_id).first()
        if not task:
            return

        # æ›´æ–°çŠ¶æ€ä¸ºå¤„ç†ä¸­
        task.status = VideoTaskStatus.PROCESSING
        task.started_at = datetime.utcnow()
        db.commit()

        # è·å– Provider
        provider = get_video_provider(task.provider)

        # åˆ›å»ºå¤–éƒ¨ä»»åŠ¡
        external_id = asyncio.run(provider.create_generation(
            prompt=task.prompt,
            duration=task.duration,
            aspect_ratio=task.aspect_ratio,
            resolution=task.resolution,
            image_url=task.input_image_url,
            last_frame_url=task.last_frame_url,
            generate_audio=task.generate_audio,
            enhance_prompt=task.enhance_prompt,
            model=task.model,
        ))

        task.external_task_id = external_id
        db.commit()

        # è½®è¯¢ç­‰å¾…å®Œæˆ
        max_wait_time = 300  # æœ€é•¿ç­‰å¾… 5 åˆ†é’Ÿ
        poll_interval = 10   # æ¯ 10 ç§’æŸ¥è¯¢ä¸€æ¬¡
        elapsed = 0

        while elapsed < max_wait_time:
            status = asyncio.run(provider.get_status(external_id))

            task.progress = status.progress or task.progress
            db.commit()

            if status.status == "completed":
                # ä¸‹è½½è§†é¢‘åˆ°å­˜å‚¨æœåŠ¡
                video_url = await download_and_store_video(
                    status.result.video_url,
                    task_id
                )

                task.status = VideoTaskStatus.COMPLETED
                task.video_url = video_url
                task.thumbnail_url = status.result.thumbnail_url
                task.actual_duration = status.result.duration
                task.completed_at = datetime.utcnow()
                db.commit()
                return

            elif status.status == "failed":
                task.status = VideoTaskStatus.FAILED
                task.error_message = status.error
                task.completed_at = datetime.utcnow()
                db.commit()
                return

            time.sleep(poll_interval)
            elapsed += poll_interval

        # è¶…æ—¶
        task.status = VideoTaskStatus.FAILED
        task.error_message = "Generation timeout"
        db.commit()

    except Exception as e:
        task.status = VideoTaskStatus.FAILED
        task.error_message = str(e)
        db.commit()
        raise self.retry(exc=e, countdown=60)

    finally:
        db.close()
```

### 5.5 è·¯ç”±å®ç°

```python
# backend/app/api/v1/video_routes.py

from fastapi import APIRouter, Depends, HTTPException, BackgroundTasks
from sqlalchemy.orm import Session
from app.core.deps import get_db, get_current_user
from app.models.video_generation import VideoGenerationTask, VideoTaskStatus
from app.tasks.video_generation import process_video_generation
from .schemas import VideoGenerateRequest, VideoGenerateResponse, VideoTaskResponse
import uuid

router = APIRouter(prefix="/v1/video", tags=["Video Generation"])

@router.post("/generate", response_model=VideoGenerateResponse)
async def generate_video(
    request: VideoGenerateRequest,
    background_tasks: BackgroundTasks,
    db: Session = Depends(get_db),
    current_user = Depends(get_current_user),
):
    """åˆ›å»ºè§†é¢‘ç”Ÿæˆä»»åŠ¡"""

    # éªŒè¯å‚æ•°
    if request.provider == "google" and request.duration > 8:
        raise HTTPException(400, "Google Veo æœ€é•¿æ”¯æŒ 8 ç§’è§†é¢‘")

    # åˆ›å»ºä»»åŠ¡è®°å½•
    task = VideoGenerationTask(
        id=str(uuid.uuid4()),
        user_id=str(current_user.id),
        prompt=request.prompt,
        provider=request.provider,
        model=request.model,
        duration=request.duration,
        aspect_ratio=request.aspect_ratio,
        resolution=request.resolution,
        input_image_url=request.image_url,
        last_frame_url=request.last_frame_url,
        enhance_prompt=request.enhance_prompt,
        generate_audio=request.generate_audio,
        status=VideoTaskStatus.PENDING,
    )

    db.add(task)
    db.commit()

    # å¯åŠ¨å¼‚æ­¥ä»»åŠ¡
    process_video_generation.delay(task.id)

    return VideoGenerateResponse(
        task_id=task.id,
        status="pending",
        created_at=task.created_at.isoformat(),
        estimated_time_seconds=120,
    )

@router.get("/tasks/{task_id}", response_model=VideoTaskResponse)
async def get_task_status(
    task_id: str,
    db: Session = Depends(get_db),
    current_user = Depends(get_current_user),
):
    """æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€"""
    task = db.query(VideoGenerationTask).filter_by(
        id=task_id,
        user_id=str(current_user.id)
    ).first()

    if not task:
        raise HTTPException(404, "Task not found")

    return VideoTaskResponse(
        task_id=task.id,
        status=task.status.value,
        progress=task.progress,
        video_url=task.video_url,
        thumbnail_url=task.thumbnail_url,
        duration=task.actual_duration,
        error={"code": task.error_code, "message": task.error_message} if task.error_message else None,
        prompt=task.prompt,
        provider=task.provider,
        created_at=task.created_at.isoformat(),
        completed_at=task.completed_at.isoformat() if task.completed_at else None,
    )

@router.delete("/tasks/{task_id}")
async def cancel_task(
    task_id: str,
    db: Session = Depends(get_db),
    current_user = Depends(get_current_user),
):
    """å–æ¶ˆç”Ÿæˆä»»åŠ¡"""
    task = db.query(VideoGenerationTask).filter_by(
        id=task_id,
        user_id=str(current_user.id)
    ).first()

    if not task:
        raise HTTPException(404, "Task not found")

    if task.status not in [VideoTaskStatus.PENDING, VideoTaskStatus.PROCESSING]:
        raise HTTPException(400, "Task cannot be cancelled")

    # å°è¯•å–æ¶ˆå¤–éƒ¨ä»»åŠ¡
    if task.external_task_id:
        provider = get_video_provider(task.provider)
        await provider.cancel(task.external_task_id)

    task.status = VideoTaskStatus.CANCELLED
    db.commit()

    return {"message": "Task cancelled"}

@router.get("/history")
async def get_history(
    limit: int = 20,
    cursor: str = None,
    db: Session = Depends(get_db),
    current_user = Depends(get_current_user),
):
    """è·å–ç”Ÿæˆå†å²"""
    query = db.query(VideoGenerationTask).filter_by(
        user_id=str(current_user.id)
    ).order_by(VideoGenerationTask.created_at.desc())

    if cursor:
        query = query.filter(VideoGenerationTask.created_at < cursor)

    tasks = query.limit(limit + 1).all()

    has_more = len(tasks) > limit
    tasks = tasks[:limit]

    return {
        "items": [task_to_response(t) for t in tasks],
        "next_cursor": tasks[-1].created_at.isoformat() if has_more else None,
    }
```

---

## å…­ã€å‰ç«¯å®ç°

### 6.1 ç›®å½•ç»“æ„

```
frontend/
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â””â”€â”€ video-service.ts        # è§†é¢‘ç”Ÿæˆ API
â”‚   â”œâ”€â”€ hooks/
â”‚   â”‚   â””â”€â”€ use-video-generation.ts # è§†é¢‘ç”Ÿæˆ Hook
â”‚   â””â”€â”€ stores/
â”‚       â””â”€â”€ video-store.ts          # è§†é¢‘ç”ŸæˆçŠ¶æ€
â”œâ”€â”€ components/
â”‚   â””â”€â”€ video/
â”‚       â”œâ”€â”€ video-generation-form.tsx    # ç”Ÿæˆè¡¨å•
â”‚       â”œâ”€â”€ video-generation-status.tsx  # çŠ¶æ€æ˜¾ç¤º
â”‚       â”œâ”€â”€ video-preview.tsx            # è§†é¢‘é¢„è§ˆ
â”‚       â””â”€â”€ video-history.tsx            # å†å²è®°å½•
```

### 6.2 æ ¸å¿ƒä»£ç 

#### lib/services/video-service.ts

```typescript
import { httpClient } from '@/http/client';

export interface VideoGenerateRequest {
  prompt: string;
  provider: 'openai' | 'google';
  duration?: number;
  aspect_ratio?: '16:9' | '9:16' | '1:1';
  resolution?: '720p' | '1080p';
  image_url?: string;
  last_frame_url?: string;
  enhance_prompt?: boolean;
  generate_audio?: boolean;
  model?: string;
}

export interface VideoTask {
  task_id: string;
  status: 'pending' | 'processing' | 'completed' | 'failed' | 'cancelled';
  progress?: number;
  video_url?: string;
  thumbnail_url?: string;
  duration?: number;
  error?: { code: string; message: string };
  prompt: string;
  provider: string;
  created_at: string;
  completed_at?: string;
}

export const videoService = {
  /**
   * åˆ›å»ºè§†é¢‘ç”Ÿæˆä»»åŠ¡
   */
  generate: async (request: VideoGenerateRequest): Promise<{ task_id: string }> => {
    const { data } = await httpClient.post('/v1/video/generate', request);
    return data;
  },

  /**
   * æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€
   */
  getTaskStatus: async (taskId: string): Promise<VideoTask> => {
    const { data } = await httpClient.get(`/v1/video/tasks/${taskId}`);
    return data;
  },

  /**
   * å–æ¶ˆä»»åŠ¡
   */
  cancelTask: async (taskId: string): Promise<void> => {
    await httpClient.delete(`/v1/video/tasks/${taskId}`);
  },

  /**
   * è·å–å†å²è®°å½•
   */
  getHistory: async (params?: { limit?: number; cursor?: string }): Promise<{
    items: VideoTask[];
    next_cursor?: string;
  }> => {
    const { data } = await httpClient.get('/v1/video/history', { params });
    return data;
  },
};
```

#### lib/hooks/use-video-generation.ts

```typescript
import { useState, useCallback, useRef, useEffect } from 'react';
import { videoService, VideoGenerateRequest, VideoTask } from '@/lib/services/video-service';

interface UseVideoGenerationOptions {
  onComplete?: (task: VideoTask) => void;
  onError?: (error: Error) => void;
  pollInterval?: number;
}

export function useVideoGeneration(options: UseVideoGenerationOptions = {}) {
  const { onComplete, onError, pollInterval = 5000 } = options;

  const [isGenerating, setIsGenerating] = useState(false);
  const [currentTask, setCurrentTask] = useState<VideoTask | null>(null);
  const pollingRef = useRef<NodeJS.Timeout | null>(null);

  // æ¸…ç†è½®è¯¢
  const stopPolling = useCallback(() => {
    if (pollingRef.current) {
      clearInterval(pollingRef.current);
      pollingRef.current = null;
    }
  }, []);

  // å¼€å§‹è½®è¯¢
  const startPolling = useCallback((taskId: string) => {
    stopPolling();

    const poll = async () => {
      try {
        const task = await videoService.getTaskStatus(taskId);
        setCurrentTask(task);

        if (task.status === 'completed') {
          stopPolling();
          setIsGenerating(false);
          onComplete?.(task);
        } else if (task.status === 'failed' || task.status === 'cancelled') {
          stopPolling();
          setIsGenerating(false);
          if (task.error) {
            onError?.(new Error(task.error.message));
          }
        }
      } catch (error) {
        stopPolling();
        setIsGenerating(false);
        onError?.(error as Error);
      }
    };

    // ç«‹å³æ‰§è¡Œä¸€æ¬¡
    poll();

    // è®¾ç½®å®šæ—¶è½®è¯¢
    pollingRef.current = setInterval(poll, pollInterval);
  }, [stopPolling, pollInterval, onComplete, onError]);

  // ç”Ÿæˆè§†é¢‘
  const generate = useCallback(async (request: VideoGenerateRequest) => {
    try {
      setIsGenerating(true);
      setCurrentTask(null);

      const { task_id } = await videoService.generate(request);

      setCurrentTask({
        task_id,
        status: 'pending',
        progress: 0,
        prompt: request.prompt,
        provider: request.provider,
        created_at: new Date().toISOString(),
      });

      // å¼€å§‹è½®è¯¢çŠ¶æ€
      startPolling(task_id);

      return task_id;
    } catch (error) {
      setIsGenerating(false);
      onError?.(error as Error);
      throw error;
    }
  }, [startPolling, onError]);

  // å–æ¶ˆç”Ÿæˆ
  const cancel = useCallback(async () => {
    if (!currentTask) return;

    try {
      await videoService.cancelTask(currentTask.task_id);
      stopPolling();
      setIsGenerating(false);
      setCurrentTask((prev) => prev ? { ...prev, status: 'cancelled' } : null);
    } catch (error) {
      onError?.(error as Error);
    }
  }, [currentTask, stopPolling, onError]);

  // æ¸…ç†
  useEffect(() => {
    return () => stopPolling();
  }, [stopPolling]);

  return {
    generate,
    cancel,
    isGenerating,
    currentTask,
    progress: currentTask?.progress ?? 0,
  };
}
```

#### components/video/video-generation-form.tsx

```tsx
import { useState } from 'react';
import { useForm } from 'react-hook-form';
import { zodResolver } from '@hookform/resolvers/zod';
import { z } from 'zod';
import { Button } from '@/components/ui/button';
import { Textarea } from '@/components/ui/textarea';
import { Select, SelectContent, SelectItem, SelectTrigger, SelectValue } from '@/components/ui/select';
import { Switch } from '@/components/ui/switch';
import { Label } from '@/components/ui/label';
import { Card } from '@/components/ui/card';
import { Upload, Wand2, Video, Loader2 } from 'lucide-react';
import { useVideoGeneration } from '@/lib/hooks/use-video-generation';
import { VideoGenerationStatus } from './video-generation-status';
import { VideoPreview } from './video-preview';

const formSchema = z.object({
  prompt: z.string().min(1, 'è¯·è¾“å…¥è§†é¢‘æè¿°').max(2000),
  provider: z.enum(['openai', 'google']),
  duration: z.number().min(4).max(25),
  aspect_ratio: z.enum(['16:9', '9:16', '1:1']),
  resolution: z.enum(['720p', '1080p']),
  enhance_prompt: z.boolean(),
  generate_audio: z.boolean(),
});

type FormData = z.infer<typeof formSchema>;

export function VideoGenerationForm() {
  const [imageUrl, setImageUrl] = useState<string | null>(null);

  const {
    generate,
    cancel,
    isGenerating,
    currentTask,
    progress,
  } = useVideoGeneration({
    onComplete: (task) => {
      console.log('Video generated:', task.video_url);
    },
    onError: (error) => {
      console.error('Generation failed:', error);
    },
  });

  const form = useForm<FormData>({
    resolver: zodResolver(formSchema),
    defaultValues: {
      prompt: '',
      provider: 'openai',
      duration: 5,
      aspect_ratio: '16:9',
      resolution: '720p',
      enhance_prompt: true,
      generate_audio: false,
    },
  });

  const provider = form.watch('provider');
  const maxDuration = provider === 'google' ? 8 : 25;

  const onSubmit = async (data: FormData) => {
    await generate({
      ...data,
      image_url: imageUrl || undefined,
    });
  };

  return (
    <div className="space-y-6">
      <Card className="p-6">
        <form onSubmit={form.handleSubmit(onSubmit)} className="space-y-6">
          {/* æç¤ºè¯è¾“å…¥ */}
          <div className="space-y-2">
            <Label>è§†é¢‘æè¿°</Label>
            <div className="relative">
              <Textarea
                {...form.register('prompt')}
                placeholder="æè¿°ä½ æƒ³è¦ç”Ÿæˆçš„è§†é¢‘å†…å®¹ï¼Œä¾‹å¦‚ï¼šä¸€åªæ©˜çŒ«åœ¨æœˆå…‰ä¸‹çš„å±‹é¡¶ä¸Šä¼˜é›…åœ°è¡Œèµ°ï¼ŒèƒŒæ™¯æ˜¯ç¹æ˜Ÿç‚¹ç‚¹çš„å¤œç©º..."
                rows={4}
                disabled={isGenerating}
              />
              <Button
                type="button"
                variant="ghost"
                size="sm"
                className="absolute right-2 top-2"
                disabled={isGenerating}
              >
                <Wand2 className="h-4 w-4 mr-1" />
                ä¼˜åŒ–
              </Button>
            </div>
          </div>

          {/* å›¾ç‰‡ä¸Šä¼  */}
          <div className="space-y-2">
            <Label>å‚è€ƒå›¾ç‰‡ (å¯é€‰)</Label>
            <div className="flex gap-4">
              <Button
                type="button"
                variant="outline"
                disabled={isGenerating}
                onClick={() => {/* ä¸Šä¼ é€»è¾‘ */}}
              >
                <Upload className="h-4 w-4 mr-2" />
                ä¸Šä¼ èµ·å§‹å¸§
              </Button>
              {imageUrl && (
                <img src={imageUrl} alt="èµ·å§‹å¸§" className="h-20 rounded" />
              )}
            </div>
          </div>

          {/* å‚æ•°è®¾ç½® */}
          <div className="grid grid-cols-2 md:grid-cols-4 gap-4">
            {/* Provider */}
            <div className="space-y-2">
              <Label>æœåŠ¡å•†</Label>
              <Select
                value={form.watch('provider')}
                onValueChange={(v) => form.setValue('provider', v as any)}
                disabled={isGenerating}
              >
                <SelectTrigger>
                  <SelectValue />
                </SelectTrigger>
                <SelectContent>
                  <SelectItem value="openai">OpenAI Sora</SelectItem>
                  <SelectItem value="google">Google Veo</SelectItem>
                </SelectContent>
              </Select>
            </div>

            {/* æ—¶é•¿ */}
            <div className="space-y-2">
              <Label>æ—¶é•¿</Label>
              <Select
                value={String(form.watch('duration'))}
                onValueChange={(v) => form.setValue('duration', Number(v))}
                disabled={isGenerating}
              >
                <SelectTrigger>
                  <SelectValue />
                </SelectTrigger>
                <SelectContent>
                  {[4, 5, 6, 7, 8, 10, 15, 20, 25]
                    .filter((d) => d <= maxDuration)
                    .map((d) => (
                      <SelectItem key={d} value={String(d)}>
                        {d} ç§’
                      </SelectItem>
                    ))}
                </SelectContent>
              </Select>
            </div>

            {/* å®½é«˜æ¯” */}
            <div className="space-y-2">
              <Label>å®½é«˜æ¯”</Label>
              <Select
                value={form.watch('aspect_ratio')}
                onValueChange={(v) => form.setValue('aspect_ratio', v as any)}
                disabled={isGenerating}
              >
                <SelectTrigger>
                  <SelectValue />
                </SelectTrigger>
                <SelectContent>
                  <SelectItem value="16:9">16:9 æ¨ªå±</SelectItem>
                  <SelectItem value="9:16">9:16 ç«–å±</SelectItem>
                  <SelectItem value="1:1">1:1 æ–¹å½¢</SelectItem>
                </SelectContent>
              </Select>
            </div>

            {/* åˆ†è¾¨ç‡ */}
            <div className="space-y-2">
              <Label>åˆ†è¾¨ç‡</Label>
              <Select
                value={form.watch('resolution')}
                onValueChange={(v) => form.setValue('resolution', v as any)}
                disabled={isGenerating}
              >
                <SelectTrigger>
                  <SelectValue />
                </SelectTrigger>
                <SelectContent>
                  <SelectItem value="720p">720p</SelectItem>
                  <SelectItem value="1080p">1080p</SelectItem>
                </SelectContent>
              </Select>
            </div>
          </div>

          {/* é«˜çº§é€‰é¡¹ */}
          <div className="flex flex-wrap gap-6">
            <div className="flex items-center gap-2">
              <Switch
                checked={form.watch('enhance_prompt')}
                onCheckedChange={(v) => form.setValue('enhance_prompt', v)}
                disabled={isGenerating}
              />
              <Label>è‡ªåŠ¨ä¼˜åŒ–æç¤ºè¯</Label>
            </div>

            {provider === 'google' && (
              <div className="flex items-center gap-2">
                <Switch
                  checked={form.watch('generate_audio')}
                  onCheckedChange={(v) => form.setValue('generate_audio', v)}
                  disabled={isGenerating}
                />
                <Label>ç”Ÿæˆé…å¥—éŸ³é¢‘</Label>
              </div>
            )}
          </div>

          {/* æäº¤æŒ‰é’® */}
          <div className="flex gap-4">
            <Button type="submit" disabled={isGenerating} className="flex-1">
              {isGenerating ? (
                <>
                  <Loader2 className="h-4 w-4 mr-2 animate-spin" />
                  ç”Ÿæˆä¸­...
                </>
              ) : (
                <>
                  <Video className="h-4 w-4 mr-2" />
                  ç”Ÿæˆè§†é¢‘
                </>
              )}
            </Button>

            {isGenerating && (
              <Button type="button" variant="outline" onClick={cancel}>
                å–æ¶ˆ
              </Button>
            )}
          </div>
        </form>
      </Card>

      {/* ç”ŸæˆçŠ¶æ€ */}
      {currentTask && (
        <VideoGenerationStatus task={currentTask} progress={progress} />
      )}

      {/* è§†é¢‘é¢„è§ˆ */}
      {currentTask?.status === 'completed' && currentTask.video_url && (
        <VideoPreview
          videoUrl={currentTask.video_url}
          thumbnailUrl={currentTask.thumbnail_url}
        />
      )}
    </div>
  );
}
```

#### components/video/video-generation-status.tsx

```tsx
import { Card } from '@/components/ui/card';
import { Progress } from '@/components/ui/progress';
import { Loader2, CheckCircle, XCircle, Clock } from 'lucide-react';
import type { VideoTask } from '@/lib/services/video-service';

interface VideoGenerationStatusProps {
  task: VideoTask;
  progress: number;
}

export function VideoGenerationStatus({ task, progress }: VideoGenerationStatusProps) {
  const statusConfig = {
    pending: {
      icon: Clock,
      text: 'æ’é˜Ÿä¸­...',
      color: 'text-yellow-500',
    },
    processing: {
      icon: Loader2,
      text: 'æ­£åœ¨ç”Ÿæˆ...',
      color: 'text-blue-500',
      animate: true,
    },
    completed: {
      icon: CheckCircle,
      text: 'ç”Ÿæˆå®Œæˆ',
      color: 'text-green-500',
    },
    failed: {
      icon: XCircle,
      text: 'ç”Ÿæˆå¤±è´¥',
      color: 'text-red-500',
    },
    cancelled: {
      icon: XCircle,
      text: 'å·²å–æ¶ˆ',
      color: 'text-gray-500',
    },
  };

  const config = statusConfig[task.status];
  const Icon = config.icon;

  return (
    <Card className="p-4">
      <div className="flex items-center gap-3 mb-3">
        <Icon
          className={`h-5 w-5 ${config.color} ${config.animate ? 'animate-spin' : ''}`}
        />
        <span className="font-medium">{config.text}</span>
        {task.status === 'processing' && (
          <span className="text-sm text-muted-foreground">
            é¢„è®¡ 1-2 åˆ†é’Ÿ
          </span>
        )}
      </div>

      {(task.status === 'pending' || task.status === 'processing') && (
        <Progress value={progress} className="h-2" />
      )}

      {task.status === 'failed' && task.error && (
        <p className="text-sm text-red-500 mt-2">{task.error.message}</p>
      )}
    </Card>
  );
}
```

#### components/video/video-preview.tsx

```tsx
import { useState, useRef } from 'react';
import { Card } from '@/components/ui/card';
import { Button } from '@/components/ui/button';
import { Play, Pause, Download, RefreshCw, Maximize } from 'lucide-react';

interface VideoPreviewProps {
  videoUrl: string;
  thumbnailUrl?: string;
}

export function VideoPreview({ videoUrl, thumbnailUrl }: VideoPreviewProps) {
  const videoRef = useRef<HTMLVideoElement>(null);
  const [isPlaying, setIsPlaying] = useState(false);

  const togglePlay = () => {
    if (videoRef.current) {
      if (isPlaying) {
        videoRef.current.pause();
      } else {
        videoRef.current.play();
      }
      setIsPlaying(!isPlaying);
    }
  };

  const handleDownload = async () => {
    const response = await fetch(videoUrl);
    const blob = await response.blob();
    const url = URL.createObjectURL(blob);
    const a = document.createElement('a');
    a.href = url;
    a.download = `video-${Date.now()}.mp4`;
    a.click();
    URL.revokeObjectURL(url);
  };

  return (
    <Card className="p-4">
      <div className="relative aspect-video bg-black rounded-lg overflow-hidden">
        <video
          ref={videoRef}
          src={videoUrl}
          poster={thumbnailUrl}
          className="w-full h-full object-contain"
          onEnded={() => setIsPlaying(false)}
        />

        {/* æ’­æ”¾æŒ‰é’®è¦†ç›–å±‚ */}
        {!isPlaying && (
          <button
            onClick={togglePlay}
            className="absolute inset-0 flex items-center justify-center bg-black/30 hover:bg-black/40 transition-colors"
          >
            <div className="w-16 h-16 rounded-full bg-white/90 flex items-center justify-center">
              <Play className="h-8 w-8 text-black ml-1" />
            </div>
          </button>
        )}
      </div>

      {/* æ§åˆ¶æ  */}
      <div className="flex items-center gap-2 mt-4">
        <Button variant="outline" size="sm" onClick={togglePlay}>
          {isPlaying ? (
            <Pause className="h-4 w-4" />
          ) : (
            <Play className="h-4 w-4" />
          )}
        </Button>

        <Button variant="outline" size="sm" onClick={handleDownload}>
          <Download className="h-4 w-4 mr-1" />
          ä¸‹è½½
        </Button>

        <Button variant="outline" size="sm">
          <RefreshCw className="h-4 w-4 mr-1" />
          é‡æ–°ç”Ÿæˆ
        </Button>

        <Button
          variant="outline"
          size="sm"
          onClick={() => videoRef.current?.requestFullscreen()}
        >
          <Maximize className="h-4 w-4" />
        </Button>
      </div>
    </Card>
  );
}
```

---

## ä¸ƒã€ä¸èŠå¤©é›†æˆ

### 7.1 åœ¨èŠå¤©ä¸­è§¦å‘è§†é¢‘ç”Ÿæˆ

å¯ä»¥é€šè¿‡è¯†åˆ«ç”¨æˆ·æ„å›¾ï¼Œåœ¨èŠå¤©ä¸­è§¦å‘è§†é¢‘ç”Ÿæˆï¼š

```typescript
// èŠå¤©æ¶ˆæ¯å¤„ç†
const handleAssistantResponse = (message: Message) => {
  // æ£€æµ‹æ˜¯å¦åŒ…å«è§†é¢‘ç”Ÿæˆè¯·æ±‚
  if (message.metadata?.video_generation) {
    const { prompt, ...params } = message.metadata.video_generation;

    // è§¦å‘è§†é¢‘ç”Ÿæˆ
    videoGeneration.generate({
      prompt,
      provider: 'openai',
      ...params,
    });
  }
};
```

### 7.2 èŠå¤©æ°”æ³¡ä¸­æ˜¾ç¤ºè§†é¢‘

```tsx
// åœ¨æ¶ˆæ¯æ°”æ³¡ä¸­åµŒå…¥è§†é¢‘é¢„è§ˆ
function MessageBubble({ message }) {
  return (
    <div className="message-bubble">
      <div className="message-content">
        {message.content}
      </div>

      {/* å¦‚æœæ¶ˆæ¯åŒ…å«è§†é¢‘ */}
      {message.video_url && (
        <div className="mt-3">
          <VideoPreview
            videoUrl={message.video_url}
            thumbnailUrl={message.video_thumbnail}
          />
        </div>
      )}
    </div>
  );
}
```

---

## å…«ã€å®æ–½è®¡åˆ’

### Phase 1: åç«¯åŸºç¡€ (2-3å¤©)
- [ ] åˆ›å»ºæ•°æ®åº“æ¨¡å‹å’Œè¿ç§»
- [ ] å®ç° OpenAI Sora Provider
- [ ] å®ç° Google Veo Provider
- [ ] åˆ›å»º API è·¯ç”±
- [ ] é…ç½® Celery å¼‚æ­¥ä»»åŠ¡

### Phase 2: å‰ç«¯åŸºç¡€ (2-3å¤©)
- [ ] åˆ›å»º Video Service API è°ƒç”¨
- [ ] å®ç° useVideoGeneration Hook
- [ ] åˆ›å»ºè§†é¢‘ç”Ÿæˆè¡¨å•ç»„ä»¶
- [ ] åˆ›å»ºçŠ¶æ€æ˜¾ç¤ºå’Œé¢„è§ˆç»„ä»¶

### Phase 3: åŠŸèƒ½å®Œå–„ (2å¤©)
- [ ] æ·»åŠ å†å²è®°å½•åŠŸèƒ½
- [ ] å®ç°å›¾ç‰‡ä¸Šä¼ å’Œ Image-to-Video
- [ ] æ·»åŠ è§†é¢‘ä¸‹è½½åŠŸèƒ½
- [ ] é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶

### Phase 4: é›†æˆå’Œä¼˜åŒ– (1-2å¤©)
- [ ] ä¸èŠå¤©åŠŸèƒ½é›†æˆ
- [ ] æ·»åŠ ç”¨é‡ç»Ÿè®¡å’Œé…é¢é™åˆ¶
- [ ] æ€§èƒ½ä¼˜åŒ–å’Œç¼“å­˜
- [ ] æµ‹è¯•å’Œæ–‡æ¡£

---

## ä¹ã€æ³¨æ„äº‹é¡¹

1. **è´¹ç”¨æ§åˆ¶**
   - è§†é¢‘ç”Ÿæˆæˆæœ¬è¾ƒé«˜ï¼Œå»ºè®®è®¾ç½®ç”¨æˆ·é…é¢
   - æä¾›ç”Ÿæˆé¢„ä¼°è´¹ç”¨æ˜¾ç¤º
   - è€ƒè™‘æŒ‰ä½¿ç”¨é‡è®¡è´¹

2. **ç”Ÿæˆæ—¶é—´**
   - è§†é¢‘ç”Ÿæˆéœ€è¦ 1-3 åˆ†é’Ÿï¼Œéœ€è¦è‰¯å¥½çš„ç­‰å¾…ä½“éªŒ
   - è€ƒè™‘ä½¿ç”¨ WebSocket å®æ—¶æ¨é€çŠ¶æ€
   - æ”¯æŒåå°ç”Ÿæˆï¼Œå®Œæˆåé€šçŸ¥

3. **å­˜å‚¨ç®¡ç†**
   - ç”Ÿæˆçš„è§†é¢‘éœ€è¦å­˜å‚¨åˆ° S3/GCS
   - è®¾ç½®è¿‡æœŸæ—¶é—´ï¼Œè‡ªåŠ¨æ¸…ç†æ—§è§†é¢‘
   - è€ƒè™‘è§†é¢‘å‹ç¼©å’Œè½¬ç 

4. **å†…å®¹å®¡æ ¸**
   - ä¸¤ä¸ª API éƒ½æœ‰å†…å®¹å®‰å…¨è¿‡æ»¤
   - æ·»åŠ æ•æ„Ÿè¯æ£€æµ‹
   - è®°å½•ç”Ÿæˆæ—¥å¿—ç”¨äºå®¡è®¡

5. **API å¯ç”¨æ€§**
   - OpenAI Sora API ç›®å‰éœ€è¦ ChatGPT Plus/Pro
   - Google Veo é€šè¿‡ Vertex AI è®¿é—®ï¼Œéœ€è¦ GCP è´¦æˆ·
   - å»ºè®®åŒæ—¶æ”¯æŒä¸¤ä¸ª Providerï¼Œäº’ä¸ºå¤‡ä»½


ä¸»æµAIè§†é¢‘ç”Ÿæˆå¹³å°APIå‚æ•°å·®å¼‚å¯¹æ¯”

1. Runway ML
æ ¸å¿ƒAPIå‚æ•°
å‚æ•°åç§°	ç±»å‹	å¿…å¡«	æè¿°	å¯é€‰å€¼/èŒƒå›´
promptImage	string	å¦	è¾“å…¥å›¾ç‰‡URLæˆ–Base64ç¼–ç ï¼Œæ”¯æŒè®¾ç½®é¦–å¸§ã€å°¾å¸§æˆ–å¤šå›¾	å›¾ç‰‡URL / Base64å­—ç¬¦ä¸²
seed	int	å¦	éšæœºç§å­ï¼Œæ§åˆ¶ç”Ÿæˆç»“æœä¸€è‡´æ€§	0-4294967295
model	enum	å¦	æ¨¡å‹ç‰ˆæœ¬	gen3aturboã€gen4turbo
promptText	string	å¦	æ–‡æœ¬æç¤ºè¯ï¼Œæè¿°æœŸæœ›çš„è§†é¢‘åŠ¨æ€æ•ˆæœ	1000å­—ç¬¦ä»¥å†…
watermark	bool	å¦	æ˜¯å¦æ·»åŠ RunwayMLæ°´å°	é»˜è®¤false
duration	enum	å¦	è§†é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰	5ã€10
ratio	enum	å¦	è§†é¢‘ç”»é¢æ¯”ä¾‹ï¼Œä¸åŒæ¨¡å‹æ”¯æŒä¸åŒ	gen3aturbo: 1280:768 / 768:1280<br>gen4turbo: 1280:720 / 720:1280 / 1:1 / 4:3 / 3:4 / 21:9

2. Pika Labs
æ ¸å¿ƒAPIå‚æ•°
å‚æ•°åç§°	ç±»å‹	å¿…å¡«	æè¿°	å¯é€‰å€¼/èŒƒå›´
pikaffect	string	å¦	å®˜æ–¹è§†é¢‘æ•ˆæœï¼Œå¯æ·»åŠ é…éŸ³å’Œç‰¹æ•ˆ	Levitateã€Decapitateã€Eye-popç­‰
promptText	string	æ˜¯	è§†é¢‘æè¿°æç¤ºè¯	ä¸é™é•¿åº¦
model	string	æ˜¯	æ¨¡å‹ç‰ˆæœ¬	1.0ã€1.5ã€2.0ã€2.2
image	string	å¦	è¾“å…¥å›¾ç‰‡URLæˆ–Base64ï¼ˆå›¾ç”Ÿè§†é¢‘æ—¶å¿…å¡«ï¼‰	æœ‰æ•ˆçš„å›¾ç‰‡URLæˆ–Base64ç¼–ç 
ingredient	array	å¦	å¤šå›¾ç”Ÿæˆæ—¶çš„å›¾ç‰‡åˆ—è¡¨ï¼ˆmodeléœ€ä¸º2.0ï¼‰	å›¾ç‰‡URLæ•°ç»„
options	object	å¦	è§†é¢‘è®¾ç½®é€‰é¡¹	aspectRatioã€frameRateã€cameraã€parametersã€extend
options.aspectRatio	float	å¦	å®½é«˜æ¯”	å¦‚16:9å¯¹åº”1.7777777777777777
options.frameRate	int	å¦	å¸§ç‡	24
options.parameters.guidanceScale	int	å¦	å¼•å¯¼ç³»æ•°	12
options.parameters.motion	int	å¦	åŠ¨æ€å¼ºåº¦	1
options.parameters.negativePrompt	string	å¦	è´Ÿå‘æç¤ºè¯	æè¿°ä¸å¸Œæœ›å‡ºç°çš„å†…å®¹

3. OpenAI Sora
æ ¸å¿ƒAPIå‚æ•°
å‚æ•°åç§°	ç±»å‹	å¿…å¡«	æè¿°	å¯é€‰å€¼/èŒƒå›´
model	string	å¦	æ¨¡å‹ç‰ˆæœ¬	sora-2ã€sora-2-pro
prompt	string	æ˜¯	è§†é¢‘æè¿°æç¤ºè¯	1-32000å­—ç¬¦
input_reference	string	å¦	å‚è€ƒå›¾ç‰‡URLï¼ˆå¤šéƒ¨åˆ†è¡¨å•ä¸Šä¼ ï¼‰	äºŒè¿›åˆ¶æ–‡ä»¶
seconds	enum	å¦	è§†é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰	4ã€8ã€12
size	enum	å¦	è§†é¢‘åˆ†è¾¨ç‡	720x1280ã€1280x720ã€1024x1792ã€1792x1024

RemixåŠŸèƒ½å‚æ•°
å‚æ•°åç§°	ç±»å‹	å¿…å¡«	æè¿°	å¯é€‰å€¼/èŒƒå›´
video_id	string	æ˜¯	å·²å®Œæˆè§†é¢‘çš„ID	è§†é¢‘ä»»åŠ¡å”¯ä¸€æ ‡è¯†ç¬¦
prompt	string	æ˜¯	æ›´æ–°çš„æ–‡æœ¬æç¤ºè¯ï¼ŒæŒ‡å¯¼ remix ç”Ÿæˆ	1-32000å­—ç¬¦

4. å­—èŠ‚è·³åŠ¨è±†åŒ…
åŸºç¡€APIå‚æ•°
å‚æ•°åç§°	ç±»å‹	å¿…å¡«	æè¿°	å¯é€‰å€¼/èŒƒå›´
model	string	æ˜¯	æ¨¡å‹ID	doubao-seedance-1-0-lite / doubao-seedance-1-0-proç­‰
promptText	string	æ˜¯	è§†é¢‘æè¿°æç¤ºè¯ï¼Œå¯è¿½åŠ --å‚æ•°å å‚æ•°å€¼æ ¼å¼çš„é…ç½®é¡¹	500å­—ç¬¦ä»¥å†…ï¼Œæ”¯æŒ--rsï¼ˆåˆ†è¾¨ç‡ï¼‰ã€--durï¼ˆæ—¶é•¿ï¼‰ã€--cfï¼ˆå›ºå®šæ‘„åƒå¤´ï¼‰ç­‰

ç»“æ„åŒ–é…ç½®å‚æ•°
å‚æ•°åç§°	ç±»å‹	å¿…å¡«	æè¿°	å¯é€‰å€¼/èŒƒå›´
resolution	string	å¦	è§†é¢‘åˆ†è¾¨ç‡	480pã€720pã€1080p
ratio	string	å¦	è§†é¢‘å®½é«˜æ¯”	16:9ã€4:3ã€1:1ã€9:16ã€3:4ã€21:9ç­‰
duration	int	å¦	è§†é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰	Seedance: 3-12ç§’ / Wan2.1: 5ç§’
fps	int	å¦	è§†é¢‘å¸§ç‡	16ã€24
watermark	bool	å¦	æ˜¯å¦æ·»åŠ æ°´å°	true/false
seed	int	å¦	éšæœºç§å­	-1åˆ°2^31-1
camera_fixed	bool	å¦	æ˜¯å¦å›ºå®šæ‘„åƒå¤´	true/false

å›¾ç”Ÿè§†é¢‘æ‰©å±•å‚æ•°
å‚æ•°åç§°	ç±»å‹	å¿…å¡«	æè¿°	å¯é€‰å€¼/èŒƒå›´
image	string	æ˜¯	é¦–å¸§å›¾åƒURLæˆ–Base64	æœ‰æ•ˆçš„å›¾ç‰‡URLæˆ–Base64ç¼–ç 
image_tail	string	å¦	å°¾å¸§å›¾åƒURLæˆ–Base64ï¼ˆé¦–å°¾å¸§å›¾ç”Ÿè§†é¢‘æ—¶å¿…å¡«ï¼‰	æœ‰æ•ˆçš„å›¾ç‰‡URLæˆ–Base64ç¼–ç 
image_role	string	å¦	é¦–å¸§å›¾ç‰‡è§’è‰²	first_frame
image_tail_role	string	å¦	å°¾å¸§å›¾ç‰‡è§’è‰²	last_frame

5. ç™¾åº¦æ–‡å¿ƒä¸€è¨€
è§†é¢‘è„šæœ¬ç”ŸæˆAPIå‚æ•°
å‚æ•°åç§°	ç±»å‹	å¿…å¡«	æè¿°	å¯é€‰å€¼/èŒƒå›´
text_input	string	æ˜¯	ç”¨æˆ·è‡ªç„¶è¯­è¨€æŒ‡ä»¤	ä»»æ„æ–‡æœ¬
target_duration	int	å¦	è§†é¢‘æ€»æ—¶é•¿ï¼ˆç§’ï¼‰	æ¨è15-60ç§’
output_format	string	å¦	è¾“å‡ºæ ¼å¼	shot_listï¼ˆç»“æ„åŒ–åˆ†é•œï¼‰
style_preference	string	å¦	é£æ ¼åå¥½	warmromanticã€scientificillustrationç­‰
temperature	float	å¦	æ§åˆ¶ç”Ÿæˆå†…å®¹éšæœºæ€§	0-2ï¼Œé»˜è®¤0.8
top_p	float	å¦	æ ¸é‡‡æ ·æ¦‚ç‡é˜ˆå€¼	0-1ï¼Œé»˜è®¤0.9

è§†é¢‘ç”ŸæˆAPIå‚æ•°
å‚æ•°åç§°	ç±»å‹	å¿…å¡«	æè¿°	å¯é€‰å€¼/èŒƒå›´
prompt	string	æ˜¯	è§†é¢‘æè¿°æç¤ºè¯	500å­—ç¬¦ä»¥å†…
negative_prompt	string	å¦	è´Ÿå‘æç¤ºè¯ï¼Œæ’é™¤ä¸å¸Œæœ›å‡ºç°çš„å†…å®¹	200å­—ç¬¦ä»¥å†…
cfg_scale	float	å¦	ç”Ÿæˆè§†é¢‘è‡ªç”±åº¦	0-1ï¼Œå€¼è¶Šå¤§ç›¸å…³æ€§è¶Šå¼º
mode	string	å¦	ç”Ÿæˆæ¨¡å¼	stdï¼ˆé«˜æ€§èƒ½ï¼‰ã€proï¼ˆé«˜è¡¨ç°ï¼‰
camera_control	object	å¦	æ§åˆ¶æ‘„åƒæœºè¿åŠ¨	åŒ…å«horizontalã€verticalã€panã€tiltã€rollã€zoomç­‰å­—æ®µ
aspect_ratio	string	å¦	è§†é¢‘å®½é«˜æ¯”	16:9ã€9:16ã€1:1
duration	int	å¦	è§†é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰	5ã€10

6. é˜¿é‡Œé€šä¹‰åƒé—®ï¼ˆwan2.2-s2vï¼‰
æ ¸å¿ƒAPIå‚æ•°
å‚æ•°åç§°	ç±»å‹	å¿…å¡«	æè¿°	å¯é€‰å€¼/èŒƒå›´
model	string	æ˜¯	æ¨¡å‹ID	wan2.2-s2v
input.image_url	string	æ˜¯	è¾“å…¥å›¾ç‰‡URL	æ”¯æŒJPGã€JPEGã€PNGã€BMPã€WEBPæ ¼å¼ï¼Œåˆ†è¾¨ç‡400-7000åƒç´ 
input.audio_url	string	å¦	è¾“å…¥éŸ³é¢‘URLï¼ˆéœ€åŒ…å«æ¸…æ™°è¯­éŸ³ï¼‰	æ”¯æŒWAVã€MP3æ ¼å¼ï¼Œæ–‡ä»¶å¤§å°â‰¤15MBï¼Œæ—¶é•¿â‰¤20ç§’
parameters.resolution	string	å¦	è§†é¢‘åˆ†è¾¨ç‡	480Pï¼ˆé»˜è®¤ï¼‰ã€720P
